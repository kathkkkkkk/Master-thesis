{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from math import pi \n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N_train = 2 ** 12, N_test = 2 ** 14): \n",
    "    \n",
    "    def f(x):\n",
    "        a = 1 / 100\n",
    "        si, ci = special.sici(x / a)\n",
    "        return si * np.exp(-x ** 2 / 2)\n",
    "\n",
    "    x_train = np.random.normal(0, 1, N_train)\n",
    "    x_train = np.reshape(x_train, (N_train, 1))\n",
    "    y_train = f(x_train)\n",
    "    \n",
    "    x_validation = np.random.normal(0, 1, N_train)\n",
    "    x_validation = np.reshape(x_validation, (N_train, 1))\n",
    "    y_validation = f(x_validation)\n",
    "    \n",
    "    x_test = np.linspace(-25 * pi, 25 * pi, N_test).reshape(N_test, 1)\n",
    "    x_test = np.reshape(x_test, (N_test, 1))\n",
    "    y_test = f(x_test)\n",
    "    \n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cut-off frequency w0\n",
    "\n",
    "def method_1_w0(x, y, px): \n",
    "    \n",
    "    # calculate f_p\n",
    "    dx = x[1] - x[0]\n",
    "    E_y = np.sum(px * y * dx)\n",
    "    fp = np.sqrt(px) * (y - E_y)\n",
    "\n",
    "    # fast Fourier transform\n",
    "    N = len(x)\n",
    "    yf = np.fft.fft(fp, axis=0)\n",
    "    \n",
    "    # the minimization function \n",
    "    dw = 2*pi/N/dx \n",
    "    K = np.linspace(-N/2, N/2-1, N)\n",
    "    f2 = np.abs(yf * dx)**2 * dw\n",
    "\n",
    "    # compute the difference \n",
    "    var_f = np.sum(f2)\n",
    "    n0 = range(0, int(N/2))\n",
    "    e_diff = np.zeros(int(N/2))\n",
    "    \n",
    "    for k in n0:\n",
    "        if k>=0 and k<=N/2-1: \n",
    "            if k==0: \n",
    "                e_low = f2[k]\n",
    "                e_high = var_f - e_low\n",
    "            else:\n",
    "                e_low = f2[0] + 2*np.sum(f2[1:k])\n",
    "                e_high = var_f - e_low\n",
    "            e_diff[k] = np.abs(e_low-e_high)\n",
    "        else: \n",
    "            print(\"index error\")\n",
    "    \n",
    "    # calculate the cut-off w0\n",
    "    e_diff_min = min(e_diff)\n",
    "    w0 = np.argmin(e_diff) \n",
    "    \n",
    "    return w0, var_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_1(var_f, w0, x_test, y_test, pred, px): \n",
    "    \n",
    "    N = len(x_test) \n",
    "    # compute r\n",
    "    r = y_test - pred\n",
    "\n",
    "    # calculate r_p\n",
    "    dx = x_test[1] - x_test[0]\n",
    "    r_mean = np.sum(px * r * dx)\n",
    "    rp = np.sqrt(px) * (r - r_mean) \n",
    "\n",
    "    # Fourier transform \n",
    "    rf = np.fft.fft(rp, axis=0)\n",
    "    rf = np.reshape(rf, (N, 1))\n",
    "\n",
    "    # compute sum_low\n",
    "    dw = 2*pi/N/dx \n",
    "    r2 = np.abs(rf * dx)**2 * dw\n",
    "    w0 = int(w0)\n",
    "    if w0==0: \n",
    "        e_low_sum = r2[w0]\n",
    "        e_high_sum = sum(r2) - e_low_sum\n",
    "    else:\n",
    "        e_low_sum = r2[0] + 2*np.sum(r2[1:w0])\n",
    "        e_high_sum = sum(r2) - e_low_sum\n",
    "\n",
    "    # compute SB\n",
    "    e_low = e_low_sum/var_f\n",
    "    e_high = e_high_sum/var_f\n",
    "    \n",
    "    SB = (e_high - e_low) / (e_high + e_low)\n",
    "    \n",
    "    return SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FVU_compute(y, pred): \n",
    "    r = y - pred \n",
    "    var_r = np.var(r)\n",
    "    var_f = np.var(y)\n",
    "    FVU = var_r/var_f \n",
    "    return FVU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "input_dim=1\n",
    "output_dim=1\n",
    "num_layers=5\n",
    "num_nodes=64\n",
    "\n",
    "activation=tf.keras.activations.relu\n",
    "kernel_initializer=tf.keras.initializers.he_normal\n",
    "bias_initializer=tf.keras.initializers.Zeros()\n",
    "# Define the network. This class corresponds to an MLP.\n",
    "# input layer\n",
    "inputs = tf.keras.Input(shape=(input_dim,), name=\"Input\")\n",
    "\n",
    "# Hidden Layers\n",
    "x = Dense(units=num_nodes, activation=activation, kernel_initializer=kernel_initializer,\n",
    "                  bias_initializer=bias_initializer)(inputs)\n",
    "for i in np.arange(1, num_layers):\n",
    "    x = Dense(units=num_nodes, activation=activation, kernel_initializer=kernel_initializer,\n",
    "                      bias_initializer=bias_initializer)(x)\n",
    "# Outputs\n",
    "outputs = Dense(output_dim, activation=\"linear\", name=\"predictions\")(x)\n",
    "if output_dim == 3:\n",
    "    outputs = Dense(output_dim, activation=\"linear\", name=\"predictions\")(x)\n",
    "\n",
    "# Compile the model\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# implement experiment 2\n",
    "\n",
    "N_train = 2 ** 12\n",
    "N_test = 2 ** 14\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "x_train, y_train, x_validation, y_validation, x_test, y_test = generate_data()\n",
    "\n",
    "# Save training values for training error evaluation\n",
    "x_train_eval = x_train\n",
    "y_train_eval = y_train\n",
    "\n",
    "# Normalize the training data\n",
    "x_mean = x_train.mean(axis=0)\n",
    "x_std = x_train.std(axis=0)\n",
    "y_mean = y_train.mean(axis=0)\n",
    "y_std = y_train.std(axis=0)\n",
    "x_train = (x_train - x_mean) / x_std\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "\n",
    "px = 1 / x_std / np.sqrt(2 * np.pi) * np.exp(-1 / 2 * (((x_test) / x_std) ** 2))\n",
    "px_train = 1 / x_std / np.sqrt(2 * np.pi) * np.exp(-1 / 2 * ((x_train / x_std) ** 2))\n",
    "px_validation = 1 / x_std / np.sqrt(2 * np.pi) * np.exp(-1 / 2 * ((x_validation / x_std) ** 2))\n",
    "\n",
    "w0, var = method_1_w0(x_test, y_test, px)\n",
    "print(w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compute_SB_Callback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "\n",
    "        # Print the training loss for every tenth epoch\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"\\nEnd of epoch  \" + str(epoch) + \", Training error \" +\n",
    "                      str(np.mean((y_train_eval - nn_predict(x_train_eval)) ** 2))) \n",
    "            \n",
    "        i = int(epoch - 1)\n",
    "                      \n",
    "        pred = nn_predict(x_train_eval)\n",
    "        pred_validation = nn_predict(x_validation)\n",
    "        FVU[i] = FVU_compute(y_train, pred)\n",
    "        FVU_validation[i] = FVU_compute(y_validation, pred_validation)\n",
    "    \n",
    "        w0, var = method_1_w0(x_test, y_test, px)\n",
    "        pred_test = nn_predict(x_test)\n",
    "        SB_ = method_1(var, w0, x_test, y_test, pred_test, px)\n",
    "        SB_M1[i] = SB_\n",
    "        \n",
    "        #print(SB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "End of epoch  0, Training error 4.084885931509151\n",
      "Epoch 1/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.7136\n",
      "Epoch 2/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.5749\n",
      "Epoch 3/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4707\n",
      "Epoch 4/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.3597\n",
      "Epoch 5/1000\n",
      "128/128 [==============================] - 0s 935us/step - loss: 0.2552\n",
      "Epoch 6/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.1730\n",
      "Epoch 7/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.1187\n",
      "Epoch 8/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0845\n",
      "Epoch 9/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0652\n",
      "Epoch 10/1000\n",
      "128/128 [==============================] - 0s 960us/step - loss: 0.0535\n",
      "\n",
      "End of epoch  10, Training error 0.06891539205230385\n",
      "Epoch 11/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0457\n",
      "Epoch 12/1000\n",
      "128/128 [==============================] - 0s 910us/step - loss: 0.0406\n",
      "Epoch 13/1000\n",
      "128/128 [==============================] - 0s 959us/step - loss: 0.0362\n",
      "Epoch 14/1000\n",
      "128/128 [==============================] - 0s 925us/step - loss: 0.0330\n",
      "Epoch 15/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0306\n",
      "Epoch 16/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0284\n",
      "Epoch 17/1000\n",
      "128/128 [==============================] - 0s 939us/step - loss: 0.0270\n",
      "Epoch 18/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0250\n",
      "Epoch 19/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0237\n",
      "Epoch 20/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0226\n",
      "\n",
      "End of epoch  20, Training error 0.030949257984519248\n",
      "Epoch 21/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0214\n",
      "Epoch 22/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0205\n",
      "Epoch 23/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0195\n",
      "Epoch 24/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0190\n",
      "Epoch 25/1000\n",
      "128/128 [==============================] - 0s 934us/step - loss: 0.0186\n",
      "Epoch 26/1000\n",
      "128/128 [==============================] - 0s 896us/step - loss: 0.0176\n",
      "Epoch 27/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0167\n",
      "Epoch 28/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0164\n",
      "Epoch 29/1000\n",
      "128/128 [==============================] - 0s 974us/step - loss: 0.0159\n",
      "Epoch 30/1000\n",
      "128/128 [==============================] - 0s 899us/step - loss: 0.0160\n",
      "\n",
      "End of epoch  30, Training error 0.020337847877654233\n",
      "Epoch 31/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0152\n",
      "Epoch 32/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0145\n",
      "Epoch 33/1000\n",
      "128/128 [==============================] - 0s 871us/step - loss: 0.0140\n",
      "Epoch 34/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0140\n",
      "Epoch 35/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0137\n",
      "Epoch 36/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0142\n",
      "Epoch 37/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0130\n",
      "Epoch 38/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0128\n",
      "Epoch 39/1000\n",
      "128/128 [==============================] - 0s 934us/step - loss: 0.0130\n",
      "Epoch 40/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0117\n",
      "\n",
      "End of epoch  40, Training error 0.015197518267760187\n",
      "Epoch 41/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0111\n",
      "Epoch 42/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0121\n",
      "Epoch 43/1000\n",
      "128/128 [==============================] - 0s 881us/step - loss: 0.0108\n",
      "Epoch 44/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0109\n",
      "Epoch 45/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0106\n",
      "Epoch 46/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0122\n",
      "Epoch 47/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0106\n",
      "Epoch 48/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0097\n",
      "Epoch 49/1000\n",
      "128/128 [==============================] - 0s 946us/step - loss: 0.0100\n",
      "Epoch 50/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0098\n",
      "\n",
      "End of epoch  50, Training error 0.024758599465249186\n",
      "Epoch 51/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0098\n",
      "Epoch 52/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0090\n",
      "Epoch 53/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0089\n",
      "Epoch 54/1000\n",
      "128/128 [==============================] - 0s 852us/step - loss: 0.0088\n",
      "Epoch 55/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0103\n",
      "Epoch 56/1000\n",
      "128/128 [==============================] - 0s 871us/step - loss: 0.0085\n",
      "Epoch 57/1000\n",
      "128/128 [==============================] - 0s 853us/step - loss: 0.0082\n",
      "Epoch 58/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0097\n",
      "Epoch 59/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0082\n",
      "Epoch 60/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0081\n",
      "\n",
      "End of epoch  60, Training error 0.01148372239108783\n",
      "Epoch 61/1000\n",
      "128/128 [==============================] - 0s 926us/step - loss: 0.0074\n",
      "Epoch 62/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0074\n",
      "Epoch 63/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0087\n",
      "Epoch 64/1000\n",
      "128/128 [==============================] - 0s 879us/step - loss: 0.0080\n",
      "Epoch 65/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 0.0124\n",
      "Epoch 66/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0140\n",
      "Epoch 67/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0074\n",
      "Epoch 68/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0079\n",
      "Epoch 69/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0074\n",
      "Epoch 70/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0071\n",
      "\n",
      "End of epoch  70, Training error 0.0320356589550832\n",
      "Epoch 71/1000\n",
      "128/128 [==============================] - 0s 887us/step - loss: 0.0070\n",
      "Epoch 72/1000\n",
      "128/128 [==============================] - 0s 881us/step - loss: 0.0095\n",
      "Epoch 73/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0066\n",
      "Epoch 74/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0066\n",
      "Epoch 75/1000\n",
      "128/128 [==============================] - 0s 884us/step - loss: 0.0071\n",
      "Epoch 76/1000\n",
      "128/128 [==============================] - 0s 888us/step - loss: 0.0078\n",
      "Epoch 77/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0066\n",
      "Epoch 78/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0068\n",
      "Epoch 79/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0068\n",
      "Epoch 80/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0066\n",
      "\n",
      "End of epoch  80, Training error 0.0369745498090766\n",
      "Epoch 81/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0066\n",
      "Epoch 82/1000\n",
      "128/128 [==============================] - 0s 875us/step - loss: 0.0077\n",
      "Epoch 83/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0065\n",
      "Epoch 84/1000\n",
      "128/128 [==============================] - 0s 851us/step - loss: 0.0063\n",
      "Epoch 85/1000\n",
      "128/128 [==============================] - 0s 886us/step - loss: 0.0102\n",
      "Epoch 86/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0076\n",
      "Epoch 87/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0066\n",
      "Epoch 88/1000\n",
      "128/128 [==============================] - 0s 909us/step - loss: 0.0058\n",
      "Epoch 89/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0088\n",
      "Epoch 90/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0076\n",
      "\n",
      "End of epoch  90, Training error 0.006595766832784176\n",
      "Epoch 91/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0068\n",
      "Epoch 92/1000\n",
      "128/128 [==============================] - 0s 910us/step - loss: 0.0061\n",
      "Epoch 93/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0064\n",
      "Epoch 94/1000\n",
      "128/128 [==============================] - 0s 890us/step - loss: 0.0050\n",
      "Epoch 95/1000\n",
      "128/128 [==============================] - 0s 896us/step - loss: 0.0097\n",
      "Epoch 96/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0057\n",
      "Epoch 97/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0127\n",
      "Epoch 98/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0051\n",
      "Epoch 99/1000\n",
      "128/128 [==============================] - 0s 910us/step - loss: 0.0252\n",
      "Epoch 100/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0056\n",
      "\n",
      "End of epoch  100, Training error 0.005981185942437049\n",
      "Epoch 101/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0052\n",
      "Epoch 102/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0071\n",
      "Epoch 103/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0084\n",
      "Epoch 104/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0056\n",
      "Epoch 105/1000\n",
      "128/128 [==============================] - 0s 889us/step - loss: 0.0055\n",
      "Epoch 106/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0055\n",
      "Epoch 107/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0064\n",
      "Epoch 108/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0053\n",
      "Epoch 109/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0052\n",
      "Epoch 110/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0048\n",
      "\n",
      "End of epoch  110, Training error 0.01294089171416373\n",
      "Epoch 111/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0055\n",
      "Epoch 112/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0058\n",
      "Epoch 113/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0065\n",
      "Epoch 114/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0907\n",
      "Epoch 115/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0061\n",
      "Epoch 116/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0052\n",
      "Epoch 117/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0050\n",
      "Epoch 118/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0047\n",
      "Epoch 119/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0051\n",
      "Epoch 120/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0044\n",
      "\n",
      "End of epoch  120, Training error 0.005120744376066597\n",
      "Epoch 121/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0053\n",
      "Epoch 122/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0056\n",
      "Epoch 123/1000\n",
      "128/128 [==============================] - 0s 888us/step - loss: 0.0044\n",
      "Epoch 124/1000\n",
      "128/128 [==============================] - 0s 885us/step - loss: 0.0041\n",
      "Epoch 125/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0049\n",
      "Epoch 126/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0045\n",
      "Epoch 127/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0043\n",
      "Epoch 128/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0059\n",
      "Epoch 129/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0043\n",
      "Epoch 130/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0041\n",
      "\n",
      "End of epoch  130, Training error 0.004793990327130793\n",
      "Epoch 131/1000\n",
      "128/128 [==============================] - 0s 880us/step - loss: 0.0046\n",
      "Epoch 132/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0082\n",
      "Epoch 133/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0043\n",
      "Epoch 134/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0053\n",
      "Epoch 135/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0075\n",
      "Epoch 136/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0043\n",
      "Epoch 137/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0046\n",
      "Epoch 138/1000\n",
      "128/128 [==============================] - 0s 893us/step - loss: 0.0074\n",
      "Epoch 139/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0060\n",
      "Epoch 140/1000\n",
      "128/128 [==============================] - 0s 893us/step - loss: 0.0051\n",
      "\n",
      "End of epoch  140, Training error 0.005565274616630311\n",
      "Epoch 141/1000\n",
      "128/128 [==============================] - 0s 939us/step - loss: 0.0050\n",
      "Epoch 142/1000\n",
      "128/128 [==============================] - 0s 869us/step - loss: 0.0061\n",
      "Epoch 143/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0039\n",
      "Epoch 144/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0062\n",
      "Epoch 145/1000\n",
      "128/128 [==============================] - 0s 893us/step - loss: 0.0055\n",
      "Epoch 146/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0047\n",
      "Epoch 147/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0049\n",
      "Epoch 148/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0041\n",
      "Epoch 149/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0041\n",
      "Epoch 150/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0041\n",
      "\n",
      "End of epoch  150, Training error 0.003910635443405877\n",
      "Epoch 151/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0113\n",
      "Epoch 152/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 153/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0037\n",
      "Epoch 154/1000\n",
      "128/128 [==============================] - 0s 888us/step - loss: 0.0045\n",
      "Epoch 155/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0037\n",
      "Epoch 156/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0044\n",
      "Epoch 157/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0051\n",
      "Epoch 158/1000\n",
      "128/128 [==============================] - 0s 918us/step - loss: 0.0040\n",
      "Epoch 159/1000\n",
      "128/128 [==============================] - 0s 908us/step - loss: 0.0032\n",
      "Epoch 160/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0038\n",
      "\n",
      "End of epoch  160, Training error 0.006990567999138584\n",
      "Epoch 161/1000\n",
      "128/128 [==============================] - 0s 891us/step - loss: 0.0051\n",
      "Epoch 162/1000\n",
      "128/128 [==============================] - 0s 926us/step - loss: 0.0038\n",
      "Epoch 163/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0044\n",
      "Epoch 164/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0040\n",
      "Epoch 165/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0038\n",
      "Epoch 166/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0038\n",
      "Epoch 167/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0133\n",
      "Epoch 168/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0037\n",
      "Epoch 169/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0028\n",
      "Epoch 170/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0029\n",
      "\n",
      "End of epoch  170, Training error 0.0034307967074243455\n",
      "Epoch 171/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0038\n",
      "Epoch 172/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0038\n",
      "Epoch 173/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0035\n",
      "Epoch 174/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0062\n",
      "Epoch 175/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0040\n",
      "Epoch 176/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0038\n",
      "Epoch 177/1000\n",
      "128/128 [==============================] - 0s 894us/step - loss: 0.0034\n",
      "Epoch 178/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0036\n",
      "Epoch 179/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0033\n",
      "Epoch 180/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0053\n",
      "\n",
      "End of epoch  180, Training error 0.003129925033626287\n",
      "Epoch 181/1000\n",
      "128/128 [==============================] - 0s 881us/step - loss: 0.0040\n",
      "Epoch 182/1000\n",
      "128/128 [==============================] - 0s 909us/step - loss: 0.0040\n",
      "Epoch 183/1000\n",
      "128/128 [==============================] - 0s 884us/step - loss: 0.0039\n",
      "Epoch 184/1000\n",
      "128/128 [==============================] - 0s 890us/step - loss: 0.0033\n",
      "Epoch 185/1000\n",
      "128/128 [==============================] - 0s 887us/step - loss: 0.0042\n",
      "Epoch 186/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 0.0043\n",
      "Epoch 187/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 0.0031\n",
      "Epoch 188/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0029\n",
      "Epoch 189/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0040\n",
      "Epoch 190/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0161\n",
      "\n",
      "End of epoch  190, Training error 0.003226547273480278\n",
      "Epoch 191/1000\n",
      "128/128 [==============================] - 0s 877us/step - loss: 0.0032\n",
      "Epoch 192/1000\n",
      "128/128 [==============================] - 0s 882us/step - loss: 0.0039\n",
      "Epoch 193/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0055\n",
      "Epoch 194/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0033\n",
      "Epoch 195/1000\n",
      "128/128 [==============================] - 0s 893us/step - loss: 0.0030\n",
      "Epoch 196/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0031\n",
      "Epoch 197/1000\n",
      "128/128 [==============================] - 0s 908us/step - loss: 0.0031\n",
      "Epoch 198/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0027\n",
      "Epoch 199/1000\n",
      "128/128 [==============================] - 0s 875us/step - loss: 0.0038\n",
      "Epoch 200/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0049\n",
      "\n",
      "End of epoch  200, Training error 0.002932792894434757\n",
      "Epoch 201/1000\n",
      "128/128 [==============================] - 0s 888us/step - loss: 0.0027\n",
      "Epoch 202/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0034\n",
      "Epoch 203/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0028\n",
      "Epoch 204/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0035\n",
      "Epoch 205/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0038\n",
      "Epoch 206/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0086\n",
      "Epoch 207/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0030\n",
      "Epoch 208/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0030\n",
      "Epoch 209/1000\n",
      "128/128 [==============================] - 0s 883us/step - loss: 0.0024\n",
      "Epoch 210/1000\n",
      "128/128 [==============================] - 0s 886us/step - loss: 0.0031\n",
      "\n",
      "End of epoch  210, Training error 0.004692401596929039\n",
      "Epoch 211/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0044\n",
      "Epoch 212/1000\n",
      "128/128 [==============================] - 0s 891us/step - loss: 0.0031\n",
      "Epoch 213/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0047\n",
      "Epoch 214/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0058\n",
      "Epoch 215/1000\n",
      "128/128 [==============================] - 0s 925us/step - loss: 0.0034\n",
      "Epoch 216/1000\n",
      "128/128 [==============================] - 0s 885us/step - loss: 0.0038\n",
      "Epoch 217/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0030\n",
      "Epoch 218/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0033\n",
      "Epoch 219/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0042\n",
      "Epoch 220/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0051\n",
      "\n",
      "End of epoch  220, Training error 0.008547082664324237\n",
      "Epoch 221/1000\n",
      "128/128 [==============================] - 0s 899us/step - loss: 0.0035\n",
      "Epoch 222/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0029\n",
      "Epoch 223/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0046\n",
      "Epoch 224/1000\n",
      "128/128 [==============================] - 0s 888us/step - loss: 0.0051\n",
      "Epoch 225/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0029\n",
      "Epoch 226/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0033\n",
      "Epoch 227/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0040\n",
      "Epoch 228/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0045\n",
      "Epoch 229/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0030\n",
      "Epoch 230/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0031\n",
      "\n",
      "End of epoch  230, Training error 0.006555059964654204\n",
      "Epoch 231/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0024\n",
      "Epoch 232/1000\n",
      "128/128 [==============================] - 0s 889us/step - loss: 0.0035\n",
      "Epoch 233/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0028\n",
      "Epoch 234/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0034\n",
      "Epoch 235/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0033\n",
      "Epoch 236/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0023\n",
      "Epoch 237/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0023\n",
      "Epoch 238/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0024\n",
      "Epoch 239/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0030\n",
      "Epoch 240/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0051\n",
      "\n",
      "End of epoch  240, Training error 0.0024079268923932677\n",
      "Epoch 241/1000\n",
      "128/128 [==============================] - 0s 909us/step - loss: 0.0023\n",
      "Epoch 242/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0023\n",
      "Epoch 243/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0029\n",
      "Epoch 244/1000\n",
      "128/128 [==============================] - 0s 908us/step - loss: 0.0028\n",
      "Epoch 245/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0031\n",
      "Epoch 246/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0029\n",
      "Epoch 247/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0029\n",
      "Epoch 248/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0070\n",
      "Epoch 249/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0054\n",
      "Epoch 250/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0027\n",
      "\n",
      "End of epoch  250, Training error 0.002289503825489624\n",
      "Epoch 251/1000\n",
      "128/128 [==============================] - 0s 896us/step - loss: 0.0023\n",
      "Epoch 252/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0024\n",
      "Epoch 253/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0055\n",
      "Epoch 254/1000\n",
      "128/128 [==============================] - 0s 873us/step - loss: 0.0021\n",
      "Epoch 255/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0032\n",
      "Epoch 256/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0047\n",
      "Epoch 257/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0024\n",
      "Epoch 258/1000\n",
      "128/128 [==============================] - 0s 890us/step - loss: 0.0041\n",
      "Epoch 259/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0053\n",
      "Epoch 260/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0029\n",
      "\n",
      "End of epoch  260, Training error 0.0028556899503921537\n",
      "Epoch 261/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0033\n",
      "Epoch 262/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0027\n",
      "Epoch 263/1000\n",
      "128/128 [==============================] - 0s 880us/step - loss: 0.0045\n",
      "Epoch 264/1000\n",
      "128/128 [==============================] - 0s 908us/step - loss: 0.0029\n",
      "Epoch 265/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0032\n",
      "Epoch 266/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0031\n",
      "Epoch 267/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0081\n",
      "Epoch 268/1000\n",
      "128/128 [==============================] - 0s 871us/step - loss: 0.0020\n",
      "Epoch 269/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 0.0027\n",
      "Epoch 270/1000\n",
      "128/128 [==============================] - 0s 909us/step - loss: 0.0019\n",
      "\n",
      "End of epoch  270, Training error 0.00215548492792886\n",
      "Epoch 271/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0071\n",
      "Epoch 272/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0023\n",
      "Epoch 273/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0025\n",
      "Epoch 274/1000\n",
      "128/128 [==============================] - 0s 865us/step - loss: 0.0022\n",
      "Epoch 275/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0030\n",
      "Epoch 276/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0026\n",
      "Epoch 277/1000\n",
      "128/128 [==============================] - 0s 896us/step - loss: 0.0033\n",
      "Epoch 278/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0027\n",
      "Epoch 279/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0029\n",
      "Epoch 280/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0024\n",
      "\n",
      "End of epoch  280, Training error 0.0022382712617978174\n",
      "Epoch 281/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0022\n",
      "Epoch 282/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0031\n",
      "Epoch 283/1000\n",
      "128/128 [==============================] - 0s 889us/step - loss: 0.0100\n",
      "Epoch 284/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0023\n",
      "Epoch 285/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0031\n",
      "Epoch 286/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0019\n",
      "Epoch 287/1000\n",
      "128/128 [==============================] - 0s 902us/step - loss: 0.0071\n",
      "Epoch 288/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0020\n",
      "Epoch 289/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0024\n",
      "Epoch 290/1000\n",
      "128/128 [==============================] - 0s 890us/step - loss: 0.0022\n",
      "\n",
      "End of epoch  290, Training error 0.0023212062560649515\n",
      "Epoch 291/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0058\n",
      "Epoch 292/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0021\n",
      "Epoch 293/1000\n",
      "128/128 [==============================] - 0s 926us/step - loss: 0.0020\n",
      "Epoch 294/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0022\n",
      "Epoch 295/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0035\n",
      "Epoch 296/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0020\n",
      "Epoch 297/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0018\n",
      "Epoch 298/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0021\n",
      "Epoch 299/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0021\n",
      "Epoch 300/1000\n",
      "128/128 [==============================] - 0s 895us/step - loss: 0.0023\n",
      "\n",
      "End of epoch  300, Training error 0.0028102725354502882\n",
      "Epoch 301/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0024\n",
      "Epoch 302/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0044\n",
      "Epoch 303/1000\n",
      "128/128 [==============================] - 0s 891us/step - loss: 0.0027\n",
      "Epoch 304/1000\n",
      "128/128 [==============================] - 0s 908us/step - loss: 0.0022\n",
      "Epoch 305/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 306/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0028\n",
      "Epoch 307/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 308/1000\n",
      "128/128 [==============================] - 0s 984us/step - loss: 0.0083\n",
      "Epoch 309/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0018\n",
      "Epoch 310/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0017\n",
      "\n",
      "End of epoch  310, Training error 0.0031294499372354788\n",
      "Epoch 311/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 312/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0026\n",
      "Epoch 313/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 314/1000\n",
      "128/128 [==============================] - 0s 997us/step - loss: 0.0024\n",
      "Epoch 315/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0019\n",
      "Epoch 316/1000\n",
      "128/128 [==============================] - 0s 994us/step - loss: 0.0032\n",
      "Epoch 317/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0031\n",
      "Epoch 318/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.0029\n",
      "Epoch 319/1000\n",
      "128/128 [==============================] - 0s 966us/step - loss: 0.0025\n",
      "Epoch 320/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0019\n",
      "\n",
      "End of epoch  320, Training error 0.0018955672437596606\n",
      "Epoch 321/1000\n",
      "128/128 [==============================] - 0s 981us/step - loss: 0.0017\n",
      "Epoch 322/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0019\n",
      "Epoch 323/1000\n",
      "128/128 [==============================] - 0s 970us/step - loss: 0.0022\n",
      "Epoch 324/1000\n",
      "128/128 [==============================] - 0s 988us/step - loss: 0.0023\n",
      "Epoch 325/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0022\n",
      "Epoch 326/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0022\n",
      "Epoch 327/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0019\n",
      "Epoch 328/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0037\n",
      "Epoch 329/1000\n",
      "128/128 [==============================] - 0s 963us/step - loss: 0.0031\n",
      "Epoch 330/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0020\n",
      "\n",
      "End of epoch  330, Training error 0.012923229094593416\n",
      "Epoch 331/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0021\n",
      "Epoch 332/1000\n",
      "128/128 [==============================] - 0s 958us/step - loss: 0.0015\n",
      "Epoch 333/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0018\n",
      "Epoch 334/1000\n",
      "128/128 [==============================] - 0s 890us/step - loss: 0.0019\n",
      "Epoch 335/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0018\n",
      "Epoch 336/1000\n",
      "128/128 [==============================] - 0s 901us/step - loss: 0.0018\n",
      "Epoch 337/1000\n",
      "128/128 [==============================] - 0s 862us/step - loss: 0.0025\n",
      "Epoch 338/1000\n",
      "128/128 [==============================] - 0s 854us/step - loss: 0.0015\n",
      "Epoch 339/1000\n",
      "128/128 [==============================] - 0s 896us/step - loss: 0.0030\n",
      "Epoch 340/1000\n",
      "128/128 [==============================] - 0s 860us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  340, Training error 0.0031792905704501277\n",
      "Epoch 341/1000\n",
      "128/128 [==============================] - 0s 806us/step - loss: 0.0030\n",
      "Epoch 342/1000\n",
      "128/128 [==============================] - 0s 854us/step - loss: 0.0028\n",
      "Epoch 343/1000\n",
      "128/128 [==============================] - 0s 899us/step - loss: 0.0044\n",
      "Epoch 344/1000\n",
      "128/128 [==============================] - 0s 882us/step - loss: 0.0024\n",
      "Epoch 345/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0019\n",
      "Epoch 346/1000\n",
      "128/128 [==============================] - 0s 881us/step - loss: 0.0019\n",
      "Epoch 347/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0018\n",
      "Epoch 348/1000\n",
      "128/128 [==============================] - 0s 992us/step - loss: 0.0017\n",
      "Epoch 349/1000\n",
      "128/128 [==============================] - 0s 935us/step - loss: 0.0019\n",
      "Epoch 350/1000\n",
      "128/128 [==============================] - 0s 998us/step - loss: 0.0024\n",
      "\n",
      "End of epoch  350, Training error 0.0016051834060979565\n",
      "Epoch 351/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0017\n",
      "Epoch 352/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0022\n",
      "Epoch 353/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0018\n",
      "Epoch 354/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0017\n",
      "Epoch 355/1000\n",
      "128/128 [==============================] - 0s 900us/step - loss: 0.0019\n",
      "Epoch 356/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0025\n",
      "Epoch 357/1000\n",
      "128/128 [==============================] - 0s 984us/step - loss: 0.0023\n",
      "Epoch 358/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0021\n",
      "Epoch 359/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.0014\n",
      "Epoch 360/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0020\n",
      "\n",
      "End of epoch  360, Training error 0.0015949592163866956\n",
      "Epoch 361/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0020\n",
      "Epoch 362/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0026\n",
      "Epoch 363/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 0.0017\n",
      "Epoch 364/1000\n",
      "128/128 [==============================] - 0s 997us/step - loss: 0.0019\n",
      "Epoch 365/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0016\n",
      "Epoch 366/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0024\n",
      "Epoch 367/1000\n",
      "128/128 [==============================] - 0s 907us/step - loss: 0.0018\n",
      "Epoch 368/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0029\n",
      "Epoch 369/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0015\n",
      "Epoch 370/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0023\n",
      "\n",
      "End of epoch  370, Training error 0.0015860383559809805\n",
      "Epoch 371/1000\n",
      "128/128 [==============================] - 0s 959us/step - loss: 0.0021\n",
      "Epoch 372/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0014\n",
      "Epoch 373/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0013\n",
      "Epoch 374/1000\n",
      "128/128 [==============================] - 0s 994us/step - loss: 0.0015\n",
      "Epoch 375/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0015\n",
      "Epoch 376/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0020\n",
      "Epoch 377/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0031\n",
      "Epoch 378/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0017\n",
      "Epoch 379/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0015\n",
      "Epoch 380/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0023\n",
      "\n",
      "End of epoch  380, Training error 0.0030325736105211937\n",
      "Epoch 381/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0016\n",
      "Epoch 382/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0023\n",
      "Epoch 383/1000\n",
      "128/128 [==============================] - 0s 934us/step - loss: 0.0024\n",
      "Epoch 384/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0024\n",
      "Epoch 385/1000\n",
      "128/128 [==============================] - 0s 934us/step - loss: 0.0020\n",
      "Epoch 386/1000\n",
      "128/128 [==============================] - 0s 944us/step - loss: 0.0022\n",
      "Epoch 387/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.0017\n",
      "Epoch 388/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 389/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0016\n",
      "Epoch 390/1000\n",
      "128/128 [==============================] - 0s 978us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  390, Training error 0.006079802456895255\n",
      "Epoch 391/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0020\n",
      "Epoch 392/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0020\n",
      "Epoch 393/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0015\n",
      "Epoch 394/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0032\n",
      "Epoch 395/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0016\n",
      "Epoch 396/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0018\n",
      "Epoch 397/1000\n",
      "128/128 [==============================] - 0s 975us/step - loss: 0.0014\n",
      "Epoch 398/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0015\n",
      "Epoch 399/1000\n",
      "128/128 [==============================] - 0s 944us/step - loss: 0.0017\n",
      "Epoch 400/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  400, Training error 0.0021183786094541835\n",
      "Epoch 401/1000\n",
      "128/128 [==============================] - 0s 959us/step - loss: 0.0016\n",
      "Epoch 402/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0022\n",
      "Epoch 403/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0019\n",
      "Epoch 404/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0020\n",
      "Epoch 405/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0026\n",
      "Epoch 406/1000\n",
      "128/128 [==============================] - 0s 962us/step - loss: 0.0016\n",
      "Epoch 407/1000\n",
      "128/128 [==============================] - 0s 946us/step - loss: 0.0014\n",
      "Epoch 408/1000\n",
      "128/128 [==============================] - 0s 986us/step - loss: 0.0028\n",
      "Epoch 409/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0029\n",
      "Epoch 410/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0016\n",
      "\n",
      "End of epoch  410, Training error 0.0015940182580405295\n",
      "Epoch 411/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0013\n",
      "Epoch 412/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0017\n",
      "Epoch 413/1000\n",
      "128/128 [==============================] - 0s 975us/step - loss: 0.0020\n",
      "Epoch 414/1000\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.0022\n",
      "Epoch 415/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 416/1000\n",
      "128/128 [==============================] - 0s 951us/step - loss: 0.0042\n",
      "Epoch 417/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0020\n",
      "Epoch 418/1000\n",
      "128/128 [==============================] - 0s 975us/step - loss: 0.0016\n",
      "Epoch 419/1000\n",
      "128/128 [==============================] - 0s 964us/step - loss: 0.0019\n",
      "Epoch 420/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0016\n",
      "\n",
      "End of epoch  420, Training error 0.0014400168309489686\n",
      "Epoch 421/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0022\n",
      "Epoch 422/1000\n",
      "128/128 [==============================] - 0s 970us/step - loss: 0.0017\n",
      "Epoch 423/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0020\n",
      "Epoch 424/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0020\n",
      "Epoch 425/1000\n",
      "128/128 [==============================] - 0s 941us/step - loss: 0.0021\n",
      "Epoch 426/1000\n",
      "128/128 [==============================] - 0s 977us/step - loss: 0.0015\n",
      "Epoch 427/1000\n",
      "128/128 [==============================] - 0s 909us/step - loss: 0.0016\n",
      "Epoch 428/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0014\n",
      "Epoch 429/1000\n",
      "128/128 [==============================] - 0s 964us/step - loss: 0.0019\n",
      "Epoch 430/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0030\n",
      "\n",
      "End of epoch  430, Training error 0.0022158785845122647\n",
      "Epoch 431/1000\n",
      "128/128 [==============================] - 0s 960us/step - loss: 0.0022\n",
      "Epoch 432/1000\n",
      "128/128 [==============================] - 0s 964us/step - loss: 0.0013\n",
      "Epoch 433/1000\n",
      "128/128 [==============================] - 0s 944us/step - loss: 0.0017\n",
      "Epoch 434/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0018\n",
      "Epoch 435/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0024\n",
      "Epoch 436/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0021\n",
      "Epoch 437/1000\n",
      "128/128 [==============================] - 0s 944us/step - loss: 0.0016\n",
      "Epoch 438/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0016\n",
      "Epoch 439/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0018\n",
      "Epoch 440/1000\n",
      "128/128 [==============================] - 0s 918us/step - loss: 0.0018\n",
      "\n",
      "End of epoch  440, Training error 0.0015090609119541866\n",
      "Epoch 441/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0021\n",
      "Epoch 442/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 443/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0020\n",
      "Epoch 444/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0017\n",
      "Epoch 445/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0051\n",
      "Epoch 446/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0024\n",
      "Epoch 447/1000\n",
      "128/128 [==============================] - 0s 979us/step - loss: 0.0029\n",
      "Epoch 448/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0035\n",
      "Epoch 449/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0017\n",
      "Epoch 450/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0013\n",
      "\n",
      "End of epoch  450, Training error 0.009938215445024132\n",
      "Epoch 451/1000\n",
      "128/128 [==============================] - 0s 964us/step - loss: 0.0022\n",
      "Epoch 452/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0013\n",
      "Epoch 453/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0018\n",
      "Epoch 454/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0013\n",
      "Epoch 455/1000\n",
      "128/128 [==============================] - 0s 955us/step - loss: 0.0015\n",
      "Epoch 456/1000\n",
      "128/128 [==============================] - 0s 973us/step - loss: 0.0015\n",
      "Epoch 457/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0015\n",
      "Epoch 458/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0017\n",
      "Epoch 459/1000\n",
      "128/128 [==============================] - 0s 986us/step - loss: 0.0044\n",
      "Epoch 460/1000\n",
      "128/128 [==============================] - 0s 935us/step - loss: 0.0016\n",
      "\n",
      "End of epoch  460, Training error 0.0016980313751401913\n",
      "Epoch 461/1000\n",
      "128/128 [==============================] - 0s 996us/step - loss: 0.0014\n",
      "Epoch 462/1000\n",
      "128/128 [==============================] - 0s 969us/step - loss: 0.0012\n",
      "Epoch 463/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0015\n",
      "Epoch 464/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0013\n",
      "Epoch 465/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 466/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0021\n",
      "Epoch 467/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0018\n",
      "Epoch 468/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0012\n",
      "Epoch 469/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0012\n",
      "Epoch 470/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0041\n",
      "\n",
      "End of epoch  470, Training error 0.0013907573131211324\n",
      "Epoch 471/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0024\n",
      "Epoch 472/1000\n",
      "128/128 [==============================] - 0s 997us/step - loss: 0.0014\n",
      "Epoch 473/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0013\n",
      "Epoch 474/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.0017\n",
      "Epoch 475/1000\n",
      "128/128 [==============================] - 0s 964us/step - loss: 0.0016\n",
      "Epoch 476/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0015\n",
      "Epoch 477/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0012\n",
      "Epoch 478/1000\n",
      "128/128 [==============================] - 0s 919us/step - loss: 0.0012\n",
      "Epoch 479/1000\n",
      "128/128 [==============================] - 0s 997us/step - loss: 0.0018\n",
      "Epoch 480/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0016\n",
      "\n",
      "End of epoch  480, Training error 0.0013282573916994843\n",
      "Epoch 481/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0017\n",
      "Epoch 482/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0025\n",
      "Epoch 483/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0014\n",
      "Epoch 484/1000\n",
      "128/128 [==============================] - 0s 971us/step - loss: 0.0016\n",
      "Epoch 485/1000\n",
      "128/128 [==============================] - 0s 983us/step - loss: 0.0013\n",
      "Epoch 486/1000\n",
      "128/128 [==============================] - 0s 996us/step - loss: 0.0021\n",
      "Epoch 487/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0018\n",
      "Epoch 488/1000\n",
      "128/128 [==============================] - 0s 960us/step - loss: 0.0022\n",
      "Epoch 489/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0013\n",
      "Epoch 490/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0022\n",
      "\n",
      "End of epoch  490, Training error 0.0013840771463674156\n",
      "Epoch 491/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 492/1000\n",
      "128/128 [==============================] - 0s 941us/step - loss: 0.0035\n",
      "Epoch 493/1000\n",
      "128/128 [==============================] - 0s 951us/step - loss: 0.0012\n",
      "Epoch 494/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0014\n",
      "Epoch 495/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0019\n",
      "Epoch 496/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0014\n",
      "Epoch 497/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0039\n",
      "Epoch 498/1000\n",
      "128/128 [==============================] - 0s 983us/step - loss: 0.0014\n",
      "Epoch 499/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0013\n",
      "Epoch 500/1000\n",
      "128/128 [==============================] - 0s 986us/step - loss: 0.0012\n",
      "\n",
      "End of epoch  500, Training error 0.001569182632835518\n",
      "Epoch 501/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0024\n",
      "Epoch 502/1000\n",
      "128/128 [==============================] - 0s 904us/step - loss: 0.0012\n",
      "Epoch 503/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 504/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0013\n",
      "Epoch 505/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0013\n",
      "Epoch 506/1000\n",
      "128/128 [==============================] - 0s 968us/step - loss: 0.0045\n",
      "Epoch 507/1000\n",
      "128/128 [==============================] - 0s 955us/step - loss: 0.0023\n",
      "Epoch 508/1000\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.0019\n",
      "Epoch 509/1000\n",
      "128/128 [==============================] - 0s 1000us/step - loss: 0.0011\n",
      "Epoch 510/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0014\n",
      "\n",
      "End of epoch  510, Training error 0.0018789805578714998\n",
      "Epoch 511/1000\n",
      "128/128 [==============================] - 0s 955us/step - loss: 0.0012\n",
      "Epoch 512/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0014\n",
      "Epoch 513/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0012\n",
      "Epoch 514/1000\n",
      "128/128 [==============================] - 0s 916us/step - loss: 0.0012\n",
      "Epoch 515/1000\n",
      "128/128 [==============================] - 0s 951us/step - loss: 0.0025\n",
      "Epoch 516/1000\n",
      "128/128 [==============================] - 0s 932us/step - loss: 0.0017\n",
      "Epoch 517/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0014\n",
      "Epoch 518/1000\n",
      "128/128 [==============================] - 0s 918us/step - loss: 0.0017\n",
      "Epoch 519/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0019\n",
      "Epoch 520/1000\n",
      "128/128 [==============================] - 0s 974us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  520, Training error 0.0012159200514902106\n",
      "Epoch 521/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0012\n",
      "Epoch 522/1000\n",
      "128/128 [==============================] - 0s 966us/step - loss: 0.0010\n",
      "Epoch 523/1000\n",
      "128/128 [==============================] - 0s 961us/step - loss: 0.0014\n",
      "Epoch 524/1000\n",
      "128/128 [==============================] - 0s 938us/step - loss: 0.0013\n",
      "Epoch 525/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0011\n",
      "Epoch 526/1000\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.0014\n",
      "Epoch 527/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0016\n",
      "Epoch 528/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0056\n",
      "Epoch 529/1000\n",
      "128/128 [==============================] - 0s 918us/step - loss: 0.0015\n",
      "Epoch 530/1000\n",
      "128/128 [==============================] - 0s 944us/step - loss: 0.0012\n",
      "\n",
      "End of epoch  530, Training error 0.0012043673407188824\n",
      "Epoch 531/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0013\n",
      "Epoch 532/1000\n",
      "128/128 [==============================] - 0s 905us/step - loss: 0.0015\n",
      "Epoch 533/1000\n",
      "128/128 [==============================] - 0s 915us/step - loss: 0.0015\n",
      "Epoch 534/1000\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.0033\n",
      "Epoch 535/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0013\n",
      "Epoch 536/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0010\n",
      "Epoch 537/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0016\n",
      "Epoch 538/1000\n",
      "128/128 [==============================] - 0s 972us/step - loss: 0.0017\n",
      "Epoch 539/1000\n",
      "128/128 [==============================] - 0s 963us/step - loss: 0.0013\n",
      "Epoch 540/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0012\n",
      "\n",
      "End of epoch  540, Training error 0.0011758019588566707\n",
      "Epoch 541/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0014\n",
      "Epoch 542/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 543/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0012\n",
      "Epoch 544/1000\n",
      "128/128 [==============================] - 0s 928us/step - loss: 0.0014\n",
      "Epoch 545/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0023\n",
      "Epoch 546/1000\n",
      "128/128 [==============================] - 0s 939us/step - loss: 0.0020\n",
      "Epoch 547/1000\n",
      "128/128 [==============================] - 0s 946us/step - loss: 0.0012\n",
      "Epoch 548/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0011\n",
      "Epoch 549/1000\n",
      "128/128 [==============================] - 0s 921us/step - loss: 0.0011\n",
      "Epoch 550/1000\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.0026\n",
      "\n",
      "End of epoch  550, Training error 0.0011543351294059363\n",
      "Epoch 551/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0013\n",
      "Epoch 552/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0032\n",
      "Epoch 553/1000\n",
      "128/128 [==============================] - 0s 913us/step - loss: 0.0016\n",
      "Epoch 554/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0014\n",
      "Epoch 555/1000\n",
      "128/128 [==============================] - 0s 931us/step - loss: 0.0015\n",
      "Epoch 556/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0013\n",
      "Epoch 557/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0011\n",
      "Epoch 558/1000\n",
      "128/128 [==============================] - 0s 978us/step - loss: 0.0014\n",
      "Epoch 559/1000\n",
      "128/128 [==============================] - 0s 942us/step - loss: 0.0011\n",
      "Epoch 560/1000\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  560, Training error 0.001198447022438074\n",
      "Epoch 561/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0012\n",
      "Epoch 562/1000\n",
      "128/128 [==============================] - 0s 961us/step - loss: 0.0013\n",
      "Epoch 563/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 564/1000\n",
      "128/128 [==============================] - 0s 914us/step - loss: 0.0030\n",
      "Epoch 565/1000\n",
      "128/128 [==============================] - 0s 943us/step - loss: 0.0012\n",
      "Epoch 566/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0012\n",
      "Epoch 567/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0014\n",
      "Epoch 568/1000\n",
      "128/128 [==============================] - 0s 999us/step - loss: 9.9048e-04\n",
      "Epoch 569/1000\n",
      "128/128 [==============================] - 0s 951us/step - loss: 0.0016\n",
      "Epoch 570/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0010\n",
      "\n",
      "End of epoch  570, Training error 0.001471667130783816\n",
      "Epoch 571/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0017\n",
      "Epoch 572/1000\n",
      "128/128 [==============================] - 0s 937us/step - loss: 0.0019\n",
      "Epoch 573/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0013\n",
      "Epoch 574/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0012\n",
      "Epoch 575/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0011\n",
      "Epoch 576/1000\n",
      "128/128 [==============================] - 0s 960us/step - loss: 0.0012\n",
      "Epoch 577/1000\n",
      "128/128 [==============================] - 0s 927us/step - loss: 0.0015\n",
      "Epoch 578/1000\n",
      "128/128 [==============================] - 0s 959us/step - loss: 0.0012\n",
      "Epoch 579/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 9.9128e-04\n",
      "Epoch 580/1000\n",
      "128/128 [==============================] - 0s 910us/step - loss: 0.0012\n",
      "\n",
      "End of epoch  580, Training error 0.0018143952401268352\n",
      "Epoch 581/1000\n",
      "128/128 [==============================] - 0s 947us/step - loss: 0.0013\n",
      "Epoch 582/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0012\n",
      "Epoch 583/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 584/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0054\n",
      "Epoch 585/1000\n",
      "128/128 [==============================] - 0s 951us/step - loss: 0.0013\n",
      "Epoch 586/1000\n",
      "128/128 [==============================] - 0s 922us/step - loss: 0.0012\n",
      "Epoch 587/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0010\n",
      "Epoch 588/1000\n",
      "128/128 [==============================] - 0s 970us/step - loss: 9.9694e-04\n",
      "Epoch 589/1000\n",
      "128/128 [==============================] - 0s 957us/step - loss: 0.0016\n",
      "Epoch 590/1000\n",
      "128/128 [==============================] - 0s 933us/step - loss: 0.0014\n",
      "\n",
      "End of epoch  590, Training error 0.0018011918892095538\n",
      "Epoch 591/1000\n",
      "128/128 [==============================] - 0s 950us/step - loss: 0.0011\n",
      "Epoch 592/1000\n",
      "128/128 [==============================] - 0s 996us/step - loss: 0.0015\n",
      "Epoch 593/1000\n",
      "128/128 [==============================] - 0s 977us/step - loss: 0.0013\n",
      "Epoch 594/1000\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.0010\n",
      "Epoch 595/1000\n",
      "128/128 [==============================] - 0s 954us/step - loss: 0.0015\n",
      "Epoch 596/1000\n",
      "128/128 [==============================] - 0s 930us/step - loss: 0.0012\n",
      "Epoch 597/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0010\n",
      "Epoch 598/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 599/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0018\n",
      "Epoch 600/1000\n",
      "128/128 [==============================] - 0s 948us/step - loss: 0.0011\n",
      "\n",
      "End of epoch  600, Training error 0.0033538564376891485\n",
      "Epoch 601/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0022\n",
      "Epoch 602/1000\n",
      "128/128 [==============================] - 0s 936us/step - loss: 0.0010\n",
      "Epoch 603/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 604/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0019\n",
      "Epoch 605/1000\n",
      "128/128 [==============================] - 0s 958us/step - loss: 0.0011\n",
      "Epoch 606/1000\n",
      "128/128 [==============================] - 0s 912us/step - loss: 0.0013\n",
      "Epoch 607/1000\n",
      "128/128 [==============================] - 0s 940us/step - loss: 0.0011\n",
      "Epoch 608/1000\n",
      "128/128 [==============================] - 0s 991us/step - loss: 0.0026\n",
      "Epoch 609/1000\n",
      "128/128 [==============================] - 0s 966us/step - loss: 0.0014\n",
      "Epoch 610/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0017\n",
      "\n",
      "End of epoch  610, Training error 0.0012678332750116457\n",
      "Epoch 611/1000\n",
      "128/128 [==============================] - 0s 924us/step - loss: 0.0011\n",
      "Epoch 612/1000\n",
      "128/128 [==============================] - 0s 978us/step - loss: 0.0019\n",
      "Epoch 613/1000\n",
      "128/128 [==============================] - 0s 949us/step - loss: 0.0011\n",
      "Epoch 614/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0012\n",
      "Epoch 615/1000\n",
      "128/128 [==============================] - 0s 898us/step - loss: 0.0012\n",
      "Epoch 616/1000\n",
      "128/128 [==============================] - 0s 929us/step - loss: 0.0012\n",
      "Epoch 617/1000\n",
      "128/128 [==============================] - 0s 971us/step - loss: 0.0011\n",
      "Epoch 618/1000\n",
      "128/128 [==============================] - 0s 897us/step - loss: 0.0012\n",
      "Epoch 619/1000\n",
      "128/128 [==============================] - 0s 965us/step - loss: 0.0012\n",
      "Epoch 620/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0015\n",
      "\n",
      "End of epoch  620, Training error 0.0010821118780461473\n",
      "Epoch 621/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 9.5815e-04\n",
      "Epoch 622/1000\n",
      "128/128 [==============================] - 0s 946us/step - loss: 0.0010\n",
      "Epoch 623/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 624/1000\n",
      "128/128 [==============================] - 0s 911us/step - loss: 0.0011\n",
      "Epoch 625/1000\n",
      "128/128 [==============================] - 0s 958us/step - loss: 0.0017\n",
      "Epoch 626/1000\n",
      "128/128 [==============================] - 0s 973us/step - loss: 0.0014\n",
      "Epoch 627/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 628/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 629/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 630/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "\n",
      "End of epoch  630, Training error 0.001609105714329586\n",
      "Epoch 631/1000\n",
      "128/128 [==============================] - 0s 956us/step - loss: 0.0011\n",
      "Epoch 632/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 633/1000\n",
      "128/128 [==============================] - 0s 979us/step - loss: 9.5884e-04\n",
      "Epoch 634/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0011\n",
      "Epoch 635/1000\n",
      "128/128 [==============================] - 0s 939us/step - loss: 9.4477e-04\n",
      "Epoch 636/1000\n",
      "128/128 [==============================] - 0s 985us/step - loss: 0.0023\n",
      "Epoch 637/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6285e-04\n",
      "Epoch 638/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 639/1000\n",
      "128/128 [==============================] - 0s 920us/step - loss: 0.0014\n",
      "Epoch 640/1000\n",
      "128/128 [==============================] - 0s 923us/step - loss: 0.0012\n",
      "\n",
      "End of epoch  640, Training error 0.0012924111925733325\n",
      "Epoch 641/1000\n",
      "128/128 [==============================] - 0s 952us/step - loss: 0.0015\n",
      "Epoch 642/1000\n",
      "128/128 [==============================] - 0s 809us/step - loss: 0.0011\n",
      "Epoch 643/1000\n",
      "128/128 [==============================] - 0s 808us/step - loss: 0.0013\n",
      "Epoch 644/1000\n",
      "128/128 [==============================] - 0s 825us/step - loss: 0.0010\n",
      "Epoch 645/1000\n",
      "128/128 [==============================] - 0s 866us/step - loss: 0.0012\n",
      "Epoch 646/1000\n",
      "128/128 [==============================] - 0s 831us/step - loss: 0.0012\n",
      "Epoch 647/1000\n",
      "128/128 [==============================] - 0s 995us/step - loss: 0.0017\n",
      "Epoch 648/1000\n",
      "128/128 [==============================] - 0s 823us/step - loss: 0.0016\n",
      "Epoch 649/1000\n",
      "128/128 [==============================] - 0s 917us/step - loss: 0.0011\n",
      "Epoch 650/1000\n",
      "128/128 [==============================] - 0s 960us/step - loss: 9.3684e-04\n",
      "\n",
      "End of epoch  650, Training error 0.006573761750047235\n",
      "Epoch 651/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 652/1000\n",
      "128/128 [==============================] - 0s 892us/step - loss: 9.8843e-04\n",
      "Epoch 653/1000\n",
      "128/128 [==============================] - 0s 903us/step - loss: 0.0014\n",
      "Epoch 654/1000\n",
      "128/128 [==============================] - 0s 984us/step - loss: 0.0012\n",
      "Epoch 655/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 656/1000\n",
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0027\n",
      "Epoch 657/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 658/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 659/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0015\n",
      "Epoch 660/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0016\n",
      "\n",
      "End of epoch  660, Training error 0.0010461165211238278\n",
      "Epoch 661/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 662/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 663/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 664/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 665/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 666/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 667/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 668/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 669/1000\n",
      "128/128 [==============================] - 0s 864us/step - loss: 0.0012\n",
      "Epoch 670/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "\n",
      "End of epoch  670, Training error 0.0010634696084693624\n",
      "Epoch 671/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 672/1000\n",
      "128/128 [==============================] - 0s 889us/step - loss: 0.0024\n",
      "Epoch 673/1000\n",
      "128/128 [==============================] - 0s 876us/step - loss: 0.0015\n",
      "Epoch 674/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 675/1000\n",
      "128/128 [==============================] - 0s 891us/step - loss: 0.0010\n",
      "Epoch 676/1000\n",
      "128/128 [==============================] - 0s 962us/step - loss: 9.1096e-04\n",
      "Epoch 677/1000\n",
      "128/128 [==============================] - 0s 881us/step - loss: 0.0019\n",
      "Epoch 678/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0033\n",
      "Epoch 679/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 680/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "\n",
      "End of epoch  680, Training error 0.0010221383451326652\n",
      "Epoch 681/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 682/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0010\n",
      "Epoch 683/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3893e-04\n",
      "Epoch 684/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 685/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 686/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 687/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9541e-04\n",
      "Epoch 688/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 689/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6994e-04\n",
      "Epoch 690/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "\n",
      "End of epoch  690, Training error 0.0011470135383030038\n",
      "Epoch 691/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 692/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 693/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 694/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9155e-04\n",
      "Epoch 695/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6546e-04\n",
      "Epoch 696/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 697/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 8.7677e-04\n",
      "Epoch 698/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 699/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0014\n",
      "Epoch 700/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "\n",
      "End of epoch  700, Training error 0.0010665265935920318\n",
      "Epoch 701/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 702/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 703/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 704/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0012\n",
      "Epoch 705/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 8.7072e-04\n",
      "Epoch 706/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0019\n",
      "Epoch 707/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 708/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 709/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 710/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2877e-04\n",
      "\n",
      "End of epoch  710, Training error 0.001047707535081729\n",
      "Epoch 711/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4510e-04\n",
      "Epoch 712/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0023\n",
      "Epoch 713/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 714/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0020\n",
      "Epoch 715/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2868e-04\n",
      "Epoch 716/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 717/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 718/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 719/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 8.6192e-04\n",
      "Epoch 720/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "\n",
      "End of epoch  720, Training error 0.0010646517853569503\n",
      "Epoch 721/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4838e-04\n",
      "Epoch 722/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8005e-04\n",
      "Epoch 723/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 724/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8598e-04\n",
      "Epoch 725/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7172e-04\n",
      "Epoch 726/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4653e-04\n",
      "Epoch 727/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1749e-04\n",
      "Epoch 728/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 729/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7709e-04\n",
      "Epoch 730/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5752e-04\n",
      "\n",
      "End of epoch  730, Training error 0.0010089637606406532\n",
      "Epoch 731/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 732/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 733/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 734/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9950e-04\n",
      "Epoch 735/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8117e-04\n",
      "Epoch 736/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 737/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 738/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 739/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 740/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8531e-04\n",
      "\n",
      "End of epoch  740, Training error 0.0011941648720246699\n",
      "Epoch 741/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.7956e-04\n",
      "Epoch 742/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9319e-04\n",
      "Epoch 743/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 744/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 745/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 746/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 747/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8658e-04\n",
      "Epoch 748/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 749/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5465e-04\n",
      "Epoch 750/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "\n",
      "End of epoch  750, Training error 0.001152255182862228\n",
      "Epoch 751/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9121e-04\n",
      "Epoch 752/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 753/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 754/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 755/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 756/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8832e-04\n",
      "Epoch 757/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 758/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6788e-04\n",
      "Epoch 759/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4055e-04\n",
      "Epoch 760/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "\n",
      "End of epoch  760, Training error 0.002825514132079036\n",
      "Epoch 761/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 762/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 763/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.7456e-04\n",
      "Epoch 764/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 765/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5090e-04\n",
      "Epoch 766/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9434e-04\n",
      "Epoch 767/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 768/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1945e-04\n",
      "Epoch 769/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1371e-04\n",
      "Epoch 770/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "\n",
      "End of epoch  770, Training error 0.0009943481975053182\n",
      "Epoch 771/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 772/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 773/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0929e-04\n",
      "Epoch 774/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 775/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 776/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 777/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 778/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2674e-04\n",
      "Epoch 779/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 780/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "\n",
      "End of epoch  780, Training error 0.0010011314952947047\n",
      "Epoch 781/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.7202e-04\n",
      "Epoch 782/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2230e-04\n",
      "Epoch 783/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8100e-04\n",
      "Epoch 784/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 785/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6780e-04\n",
      "Epoch 786/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 787/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4371e-04\n",
      "Epoch 788/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5147e-04\n",
      "Epoch 789/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 790/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0573e-04\n",
      "\n",
      "End of epoch  790, Training error 0.0011034042444949227\n",
      "Epoch 791/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2408e-04\n",
      "Epoch 792/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 793/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 794/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 795/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 796/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 797/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4596e-04\n",
      "Epoch 798/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 799/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 800/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "\n",
      "End of epoch  800, Training error 0.001150827148245409\n",
      "Epoch 801/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1913e-04\n",
      "Epoch 802/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5431e-04\n",
      "Epoch 803/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0054e-04\n",
      "Epoch 804/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2757e-04\n",
      "Epoch 805/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 806/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 807/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6566e-04\n",
      "Epoch 808/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 809/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 810/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7178e-04\n",
      "\n",
      "End of epoch  810, Training error 0.0010950385801053728\n",
      "Epoch 811/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 812/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 813/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1892e-04\n",
      "Epoch 814/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8177e-04\n",
      "Epoch 815/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 816/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 817/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0029\n",
      "Epoch 818/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2212e-04\n",
      "Epoch 819/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5328e-04\n",
      "Epoch 820/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4667e-04\n",
      "\n",
      "End of epoch  820, Training error 0.0009600123104264108\n",
      "Epoch 821/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2932e-04\n",
      "Epoch 822/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5352e-04\n",
      "Epoch 823/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 824/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.7981e-04\n",
      "Epoch 825/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5037e-04\n",
      "Epoch 826/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 827/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9267e-04\n",
      "Epoch 828/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0017\n",
      "Epoch 829/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 830/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8857e-04\n",
      "\n",
      "End of epoch  830, Training error 0.0009676842196038053\n",
      "Epoch 831/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4868e-04\n",
      "Epoch 832/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9201e-04\n",
      "Epoch 833/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0097e-04\n",
      "Epoch 834/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4003e-04\n",
      "Epoch 835/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 836/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9347e-04\n",
      "Epoch 837/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5829e-04\n",
      "Epoch 838/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.9852e-04\n",
      "Epoch 839/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 840/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3935e-04\n",
      "\n",
      "End of epoch  840, Training error 0.0010042161811083224\n",
      "Epoch 841/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.9514e-04\n",
      "Epoch 842/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 843/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 844/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7131e-04\n",
      "Epoch 845/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8921e-04\n",
      "Epoch 846/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 847/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5424e-04\n",
      "Epoch 848/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7674e-04\n",
      "Epoch 849/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5639e-04\n",
      "Epoch 850/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5306e-04\n",
      "\n",
      "End of epoch  850, Training error 0.001120336153197995\n",
      "Epoch 851/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3835e-04\n",
      "Epoch 852/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6422e-04\n",
      "Epoch 853/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3319e-04\n",
      "Epoch 854/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5093e-04\n",
      "Epoch 855/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 856/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.7272e-04\n",
      "Epoch 857/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5599e-04\n",
      "Epoch 858/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3132e-04\n",
      "Epoch 859/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 860/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "\n",
      "End of epoch  860, Training error 0.00178032142649457\n",
      "Epoch 861/1000\n",
      "128/128 [==============================] - 0s 2ms/step - loss: 0.0011\n",
      "Epoch 862/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3295e-04\n",
      "Epoch 863/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6056e-04\n",
      "Epoch 864/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2343e-04\n",
      "Epoch 865/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 866/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 867/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4092e-04\n",
      "Epoch 868/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7098e-04\n",
      "Epoch 869/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 870/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.1625e-04\n",
      "\n",
      "End of epoch  870, Training error 0.0009438302364527798\n",
      "Epoch 871/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0970e-04\n",
      "Epoch 872/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0957e-04\n",
      "Epoch 873/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 874/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8494e-04\n",
      "Epoch 875/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4271e-04\n",
      "Epoch 876/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0016\n",
      "Epoch 877/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5274e-04\n",
      "Epoch 878/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6696e-04\n",
      "Epoch 879/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0024\n",
      "Epoch 880/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1885e-04\n",
      "\n",
      "End of epoch  880, Training error 0.001111373358616802\n",
      "Epoch 881/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.4738e-04\n",
      "Epoch 882/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0741e-04\n",
      "Epoch 883/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.2501e-04\n",
      "Epoch 884/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7300e-04\n",
      "Epoch 885/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9142e-04\n",
      "Epoch 886/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3796e-04\n",
      "Epoch 887/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7960e-04\n",
      "Epoch 888/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5671e-04\n",
      "Epoch 889/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.4992e-04\n",
      "Epoch 890/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "\n",
      "End of epoch  890, Training error 0.001094518073963662\n",
      "Epoch 891/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1704e-04\n",
      "Epoch 892/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.1412e-04\n",
      "Epoch 893/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5493e-04\n",
      "Epoch 894/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3135e-04\n",
      "Epoch 895/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.8729e-04\n",
      "Epoch 896/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.2759e-04\n",
      "Epoch 897/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 898/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.2412e-04\n",
      "Epoch 899/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0018\n",
      "Epoch 900/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0363e-04\n",
      "\n",
      "End of epoch  900, Training error 0.0012783986476600081\n",
      "Epoch 901/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3919e-04\n",
      "Epoch 902/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0161e-04\n",
      "Epoch 903/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8582e-04\n",
      "Epoch 904/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8412e-04\n",
      "Epoch 905/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 906/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5483e-04\n",
      "Epoch 907/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 908/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4719e-04\n",
      "Epoch 909/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8098e-04\n",
      "Epoch 910/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9963e-04\n",
      "\n",
      "End of epoch  910, Training error 0.0009251757511076141\n",
      "Epoch 911/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0022\n",
      "Epoch 912/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9000e-04\n",
      "Epoch 913/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6269e-04\n",
      "Epoch 914/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4173e-04\n",
      "Epoch 915/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 916/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 917/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5987e-04\n",
      "Epoch 918/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3164e-04\n",
      "Epoch 919/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 920/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9128e-04\n",
      "\n",
      "End of epoch  920, Training error 0.00563196617631429\n",
      "Epoch 921/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.3185e-04\n",
      "Epoch 922/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0014\n",
      "Epoch 923/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 924/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5097e-04\n",
      "Epoch 925/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.8906e-04\n",
      "Epoch 926/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8512e-04\n",
      "Epoch 927/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.6376e-04\n",
      "Epoch 928/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 929/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.1925e-04\n",
      "Epoch 930/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0833e-04\n",
      "\n",
      "End of epoch  930, Training error 0.0024251144237586713\n",
      "Epoch 931/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0452e-04\n",
      "Epoch 932/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4334e-04\n",
      "Epoch 933/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 934/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.6936e-04\n",
      "Epoch 935/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0501e-04\n",
      "Epoch 936/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 937/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 938/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0015\n",
      "Epoch 939/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 940/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "\n",
      "End of epoch  940, Training error 0.0012020602464099584\n",
      "Epoch 941/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8393e-04\n",
      "Epoch 942/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8274e-04\n",
      "Epoch 943/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3537e-04\n",
      "Epoch 944/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3713e-04\n",
      "Epoch 945/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 946/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4806e-04\n",
      "Epoch 947/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.8747e-04\n",
      "Epoch 948/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4910e-04\n",
      "Epoch 949/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.9834e-04\n",
      "Epoch 950/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4758e-04\n",
      "\n",
      "End of epoch  950, Training error 0.0009389052335385315\n",
      "Epoch 951/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0903e-04\n",
      "Epoch 952/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 953/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0690e-04\n",
      "Epoch 954/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6222e-04\n",
      "Epoch 955/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.0977e-04\n",
      "Epoch 956/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "Epoch 957/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.1543e-04\n",
      "Epoch 958/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3404e-04\n",
      "Epoch 959/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8916e-04\n",
      "Epoch 960/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0010\n",
      "\n",
      "End of epoch  960, Training error 0.0010007066880146928\n",
      "Epoch 961/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9700e-04\n",
      "Epoch 962/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3083e-04\n",
      "Epoch 963/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2962e-04\n",
      "Epoch 964/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2615e-04\n",
      "Epoch 965/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0024e-04\n",
      "Epoch 966/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5001e-04\n",
      "Epoch 967/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.8069e-04\n",
      "Epoch 968/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 969/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.1775e-04\n",
      "Epoch 970/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.5673e-04\n",
      "\n",
      "End of epoch  970, Training error 0.002321796519683275\n",
      "Epoch 971/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 972/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.8170e-04\n",
      "Epoch 973/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 974/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.9146e-04\n",
      "Epoch 975/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 976/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0011\n",
      "Epoch 977/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 978/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.8802e-04\n",
      "Epoch 979/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.3548e-04\n",
      "Epoch 980/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "\n",
      "End of epoch  980, Training error 0.0010673435692846354\n",
      "Epoch 981/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.2386e-04\n",
      "Epoch 982/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.0012\n",
      "Epoch 983/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5355e-04\n",
      "Epoch 984/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6952e-04\n",
      "Epoch 985/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0347e-04\n",
      "Epoch 986/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4407e-04\n",
      "Epoch 987/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.9277e-04\n",
      "Epoch 988/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.7126e-04\n",
      "Epoch 989/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.2205e-04\n",
      "Epoch 990/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.0554e-04\n",
      "\n",
      "End of epoch  990, Training error 0.0008889863353411605\n",
      "Epoch 991/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.7069e-04\n",
      "Epoch 992/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.5055e-04\n",
      "Epoch 993/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.4098e-04\n",
      "Epoch 994/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.5999e-04\n",
      "Epoch 995/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.1991e-04\n",
      "Epoch 996/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.6797e-04\n",
      "Epoch 997/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.4954e-04\n",
      "Epoch 998/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 9.2186e-04\n",
      "Epoch 999/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 7.8696e-04\n",
      "Epoch 1000/1000\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 8.7445e-04\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 1000\n",
    "num_evals=100\n",
    "mod = int(epochs / num_evals)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1).batch(batch_size)\n",
    "\n",
    "loss_fn = tf.keras.losses.mean_squared_error\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "def nn_predict(x):\n",
    "    x = (x - x_mean) / x_std\n",
    "    beta = model(x) * y_std + y_mean\n",
    "    return beta.numpy()\n",
    "\n",
    "FVU = np.zeros(epochs)\n",
    "FVU_validation = np.zeros(epochs)\n",
    "SB_M1 = np.zeros(epochs)\n",
    "\n",
    "SB_callback = Compute_SB_Callback()\n",
    "tf.random.set_seed(seed)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn)\n",
    "beta = model.fit(x_train, y_train, epochs=epochs, batch_size=32, callbacks=[SB_callback])\n",
    "\n",
    "my_loss = beta.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA/uUlEQVR4nO2deZgU1bn/v2/PxgwM27DNsA7IKgrCgAqIIGiQgCPiAiZgchXjVZ4bTeKNuXjDD00eNe7muuHC1ai4K8bdoMQYc9GBKIuAjANhh5F9H2b6/P7orqa6uqq6llNLd7+f55lnuqvOVtVV5z3vcs4hIQQYhmGY3CUSdAMYhmGYYGFBwDAMk+OwIGAYhslxWBAwDMPkOCwIGIZhcpz8oBvghHbt2okePXoE3QyGYZiMYtmyZd8LIdprj2ekIOjRowdqamqCbgbDMExGQUT/0jsuxTRERE8T0S4iWmVwnojoISKqJaIVRDREdW4CEa2Ln7tFRnsYhmEY68jyEfwvgAkm5y8E0Dv+dy2ARwGAiPIAPBw/PwDAdCIaIKlNDMMwjAWkCAIhxKcA9pgkqQbwrIjxfwBaE1E5gOEAaoUQdUKIBgAvxtMyDMMwPuFX1FBnAJtV37fEjxkdT4GIriWiGiKqqa+v96yhDMMwuYZfgoB0jgmT46kHhZgvhKgSQlS1b5/i9GYYhmEc4lfU0BYAXVXfuwDYBqDQ4DjDMAzjE35pBG8BmBmPHjoLwH4hxHYAXwLoTUSVRFQIYFo8LcMwDOMTUjQCIloIYAyAdkS0BcBcAAUAIIR4DMC7ACYCqAVwBMBP4+caiWg2gA8A5AF4WgixWkabzBBC4Ouvv8aAAQNQWFjodXUMwzChRoogEEJMT3NeALjB4Ny7iAkK39i8eTMWLVqEzZs3Y/LkyX5WzTAMEzpycq2hl156CQDw/fffB9wShmGY4MnIJSbccuTIEQDApk2bsGzZMqxduxbFxcW45JJLAm4ZwzCM/+SkRlBWVpb4/Pbbb6O2thYrV65EU1NTgK1iGIYJhpwUBNFoFPn5+SguLk46/rvf/Q5/+tOfcPz48YBaxjAM4z85KQhOnDiB008/HTfffHPKubq6Ojz//PPYvHkzXnzxRTz77LMBtJBhGMY/ctJHcOLECRQUFIBIb2JzLKro6aefTjp25MgR/OMf/8DYsWMRieSk/GQYJkvJyR5NEQQALDuI33nnHXz22Wf49ttv8eabb+Lw4cNeNpFhGMY3ck4QNDU1IRqNJgTBwIED0aJFC8P0ZWVluOOOO/DNN98AANasWYOvv/4aixcvBgDs378/EYXEMAyTieScIDhx4gQAID8/ZhUjIvzgBz8wTB+NRtHQ0JD4vmPHDgCx2clbt27FAw88gLvvvhvr1q3zsNUMwzDekXOCIBqNAgDy8vIspY9Nij7Jrl27EsfVnf+3334rqYUMwzD+woJARa9evVKO7du3T7ecr7/+Gnv37k18P3r0KABg9+7drB0wDJNR5FzUkCII1JE/yqi/WbNmiWOVlZXYsGGDaVmrVp3connnzp2YN29e4vvcuXOltJdhGMZrck4jUGYP64WAqsNJZ86ciaFDh1oud88es506GYZhwkvOCQIzjUCL0TwDKyxZssRxXoZhGD9hQYCYGQgAhg8fnpTWzcSxv/71rwCAgwcP4vXXX8exY8ccl8UwDOMlLAgAlJaWYu7cuejatStmz56NG26IbZ3gRiNQWL16NVauXImPP/5Y9/y+ffvwzjvvIBqNoq6uDvPmzcP+/ftd18swDGMVFgQaysrK0K5dO9M0VmloaEDLli0BnAw71fLmm2+ipqYGW7ZsQU1NDQBg69atAICFCxdi7dq1rtrAMAyTjpwVBFbmEbjVCO64446E/2H79u246667cN999yVmKQMnJ7gtWLAA3333HQDglVdewfHjx/Htt9/ipZdewr59+3Dbbbdh586drtrDMAyjR84KAiujfRmLyyn1NTQ04NixYzh48CBeeeUVAMBHH32Ebdu2JdKqZzArcxEikQhqa2shhMDSpUtdt4dhGEaLFEFARBOIaB0R1RLRLTrnbyair+J/q4ioiYjaxs9tJKKV8XM1Mtpjhln4qBYZgkAvIomIsGPHDnz++eeG+Xbv3g0AKCwsRPPmzQHE1jW64447eBYzwzBScd3TEVEegIcBXAhgAIDpRDRAnUYIcbcQYrAQYjCA3wD4qxBCHXg/Nn6+ym170mFHI5DhLNYTBMXFxWk7808//TSRf/v27QBiW2s2NDQYOp4ZhrGPH8EZ3377ra090r/66ivDVQ28QIZGMBxArRCiTgjRAOBFANUm6acDWCihXkcEZRrSHlObgcw4fvw4/va3vwEAGhsbXbeHYZiT1NXV4YEHHkjy29mloaEBGzduTDq2Z8+epKXqFy5ciIcffthSeY2NjVi0aBGeeeYZx22yiwxB0BnAZtX3LfFjKRBRCYAJAF5THRYAPiSiZUR0rVElRHQtEdUQUU19fb3jxvqtEehF/QwYMED6vAJFSOzYsQPLli1zXM7hw4d572YmcPbv34/Vq1enHfycOHECDz30EObPn284MdSMLVu2AEBC69ZjxYoVmDdvXqJjX79+fVIn/8ILL+CZZ55J2uL2j3/8Ix566CFLbVi2bBnmzZuHefPm4YEHHki8f0od77//PubNm4fnn3/e3sXZQMZaQ3q9pdEvMhnA3zVmoZFCiG1E1AHAR0S0VgjxaUqBQswHMB8Aqqqq7P/icexEDcnQCLQmoLy8POTl5bnew2DevHkYMmQIJk+ejLVr1+Kll17Cz372Mzz++OMAYGt5DIVoNIp77rkHgwYNwsUXX+yqfYz37Nq1C4cPH05MiMwG7rjjDlRWViaCJYYNG4aJEycapn/33XcTiz+eOHEChYWFtupTNHMlek+hrq4O5eXlKC4uTvjy9u/fj6KiIrzwwgvo2LEjrrvuOgDAv/71LwCp2n9DQwNWrVqFzZtPjpOj0Sh27NiBkpISFBYWoqSkBG+//Xbi/P79+xPlKANRJUiktrYWx44dS1oTTRYyBMEWAF1V37sA2GaQdho0ZiEhxLb4/11E9AZipqYUQSALOxqBFygPqrJaqROUMNLly5cnBAFwcq8EAPjwww8xbtw4HDhwAC+99BL69OmDqqoq/OUvf0HPnj1x6qmnAkBigx4ACeHEcxfCzZEjR7Bjxw786U9/AhBb4DAajaKpqSnp9wwzQggsWbIEgwcPRps2bRLHGxoaklbvVdvJ9+7di6KiIpSUlCSOqe3ujY2NSYJg3bp1OHToUGJQdOLECdx1112YPHkyBg0alDgGxDrbzZs3o6SkBJdcckni3t54442J9y0/Pz/xWW9ekGLyVZuJXnvttaQ0r776KtasWZP4ftlll6WUo2hBDQ0NeOGFF5LOnThxIrSC4EsAvYmoEsBWxDr7K7WJiKgVgHMB/Fh1rDmAiBDiYPzzBQBuk9AmQ+xEDWnp0KEDWrdu7ThqR9kMRwjhShBo0W62AwD/+Mc/UFFRgY0bN2Lnzp3YuXMnVq9ejT179mDlypVYtGgRmjVrhl//+teJPIcOHQJwchXWvXv3Jr2kjLds3LgRJSUl6NChQ9Lx5cuX489//jPmzJmD/Px8LFy4MGHSUFA6mP/+7/8GEUkxa1qhsbERu3btQkVFheU8hw8fxpNPPol9+/Zh+/btuPLKWHeh509To5hapkyZgtNPPx1AcjDGwoULMX369ISgePHFFwGc1I6PHj2KpqYmvPnmm2jTpg0WLlyIHj16JPIrodxKPgB49NFHE5+bmprw5JNPJur9+OOP0bXryTHwnj17UvY616IWAkDst9WiNs2uX78+6ZxXfkLXw2IhRCOA2QA+ALAGwMtCiNVEdB0RXadKOgXAh0II9Wa/HQF8RkRfA/gCwDtCiPfdtskMOxqB1ubYokULTJ8+Heeee66juvPy8hIvqExBoDwc2tHg8ePHkx4c7Qqpx44dw7x58xKqtVoQrF+/Hg899FDKgxsEGzZsSOn4ZFBXV4f33ntPerlOeeaZZ5I6HoWPPvoIwEkzhp6PTPmdbr/9djz44IOW6nv55Zfx5z//OelYY2MjvvjiCwghcPz4cdTV1SXZvhX27NmDb775Bu+99x6eeOKJxMg9Go3i/fffx4EDB7B161Y8/vjjOHr0KLZv3477778fK1euxPLlyxPp1dvE6i37vm3btqTl3gHgjTfewIEDB1IGZFu2bMETTzwBIPke6fnjFixYgGPHjulqv5s2bUp8Vl+7NsDjb3/7W9KI/ZNPPkkpKx16AtvMR+dV6LiU/QiEEO8CeFdz7DHN9/8F8L+aY3UABslog1WUjlE9ejZCKwiUH82JUwo46ZfwQyMAYg+u1vapxzfffIORI0cmCQJFaNTV1aF///7S2uqEZ599FoD8PR4U9f/CCy9MOffpp5+itLQUrVq1wpEjRzBw4EBLZR49ehT19fXo1q2btHZqO2LtIObgwYNJ3/fv34+amhps374dkydPNixXER5jx47FwoUL0dDQgD59+uDzzz9HSUkJPvvsM+zcuRPt2rVDJBJBSUkJNm7ciOuvvx4LFizA0aNH0bFjRwCx627dujU2b96MpUuXor6+HkePHsWOHTvwz3/+EwUFBThw4ABef/31pDY0a9YMW7Zswb59+1LMKEBMe3jttdfQtm3bpOP3338/AKRoIvv27UvaFwSImWdqa2sxePBgw3thBS86Yb3oQTNB8P777+PMM8+U3o6c25hG6Rit2FK1Iwm36nZeXh6i0Sii0ajuKMspinDTOsC3bt1qKyxOiVJo1qxZYqSmjo4ImvXr16N3796G5zdt2oRoNJqk7ttF+X20ozutILj33nvRv3//FEfmCy+8gC1btuDWW29NEvxCCF0tNBqNYu3atWjfvr1uew4cOJAYeGidiAr33XdfSr533nkHABKCIBqNJtWv/l3VkSpdunQBELvXij1cG/9eV1eXGMholz1R6tiwYUOi3YpGY8RTTz1leh5AYqSvJZ05CYg5WYFYbL4bzCaAOkWvHwgiai/nlpiwoxF06tQp6btWI1BeGqsoL4kiYGTYcaPRaEK4aTWV1atX2ypL0QgikUhilKkVBPv27cO+ffvw1VdfJY1motGoaQieHo2NjfjrX/9qavdUX4PWcaZlwYIFprHXVjS5Z599Fr///e9Tjr/33nuor69PmC8OHTqEL7/8MiWdYsJSX9Mrr7yC22+/Xbe+v//973jllVfwyCOPpJw7evRoYuSrbr9d/9Z3332H22+/PWk5kzfffDPxWd3xKHWsWLHCsDwhBIqLi5OOKc/0gQMHkspJh9swajudpt2IIrs4sRToCTK7760Mck4QGJlR9Bg4cGBSOm3HXV5ebqvuSCQCIkqMAoqKimzl16O2tjbR6Tg1WX3zzTe45557EjMsN23ahA8++ABAqnPqwQcfxIMPPohFixbhjjvuSBxfsmQJ5s+fnxS5FI1GE6NhPZYuXYolS5bg97//PR577DHdNMpkOjsYdS533nmn4cjy2LFjEEIkQgG1fPHFF3jkkUcSZqp0qO+bYoI5dOgQ5s2blwgnPHHihOl2qFqh9sgjj+D999+3paUdOXIEzz33HAAkzS8xMk1aGWEDSBEEzz77LFauXIlXX33VctsA4J///Ket9FrsOE+DihQ0Q+/dUFYh9pPw3RmPOXHiBPLz8y2NxokoaRQhy0cgM4RV/eI6bde2bdtw+PDhxGhW3dFY7RgUbUCtSdx+++344osvcNtttyXt2PbSSy/h3nvvTfJf7Ny5UzckT/s7ffLJJwlTxeeff4533nknZVSoOIB3796dJEgaGhqSRsUKhw8fxl133ZVY1kMGjY2NOHz4cJI54t577wUQ0wJWr16Nl19+WVcQRKNRPProoylml2PHjmHp0qW2fue777478Xn58uWJe2z07FkxWX7wwQe6+bX2fz9QAh2s4FcklR30fks2DflAY2OjrVhrs5fOzoPVuXNnTJ48GUQUOkGgoHU6AukfyiNHjuDYsWOJe6G0R4naUNZFUkY5S5Yswdq1a3Ho0KGU0LlDhw5h3759pg7uTz/9NDHC/eijj1BTU5NkPgFOCrIFCxbg448/Tunc1q9fn+RQVK7b6vai2vu8cePGFE2isbERzz33HBYtWpSSf926dXj11VcTtmstu3fvNty/wi2K+c/o2bXqEPVjfZ5zzjlHankyAzT0cPL+KYtLqrE6+JJJTjqLrZiFrGBHEFxzzTWJPErnKmtRO6UcL1RKs4eyZcuWuPvuu0FE6NOnT6I9n3zySaIzVvwIrVu3BhAbDStoBc/Ro0fx4IMPorKyEjNnzjSsV2v60ZpKFEGvHNeap7ROP2U2tlW05gjFhKOOampsbEwyk9nBy47g66+/BuB+EGIlGi3XMDIr2sXs9+/Zs6eUOrTknCCwqxHooXQqTjtypxpBcXFxyqhGLQjUMzJlYfZQqh2DSt1CCF0Ti9LG/Px8Q7uuMnJXm0v07rFem8xGe9ooLe0CYXYxMp+ohY2baCurCxI6YcWKFVixYoVnHYosevXqFUpTTtB4dU9y0jTkViNwIwjUpiG7+fUEx2uvvWarHLuRTnbtlUbOwkgkgqamJtPy9FRrvU5fr4w//OEPic/FxcVJk+ei0air6BTt/TUqSy3glDkKTvBSECh45Tg95ZRT0Lmz7pqTlpkyZQqmTZtmK4+icTLOyDlBoI2nTocsH4G2DYD9l9HKQnnpSCcEtS+UsoaN1RGukQaxadMm/O53vzM1KahNKeqZqlbrUNi4cSP++Mc/Jr67ncCnDTtUz3JWOytlmUv8EARejSzLyspcl92yZcuUgA71+kJaxo8fn1hyIttx6wc0IucEQVNTk+sO1c2P4cZZbJTezouXThC0a9cu6fuhQ4fw+OOP45577vHciaX2cTz44IMpS2QopLtv2kgStxqB1pSomMSAZP/CF1984bgONX4IAq+wGpFnhjZ/p06dktb00eJ1WKibCYqyYUEgCbsagRluNQK7+WWM4tIJgpYtW6YcUyKA/N4Yx8iUVFBQYGvGdDQadaURaO+Zetax2l8ga+aperKXV3jVoQDun1Mlv/q/2TvrtSAYPXq0p+XbgQWBJNxoBEZrD9lBdvioXdIJAvUiYFq8cEabEYlEUjQUIGYie+WVVyyXI9tHYITsSJrLL79canlqvBQEbtHe73SrqXrtVM4FpzULgjTovTBuXyKn4aNG6e10QOkEQWlpqeG5ICYMNTY2okePHilLMxuhN1tbCOGqkw6qI/BySQSvBIGMJbC1GgFgPmgiIvTr189VnVbaEwZYI5BE0KYhpxrB7NmzDc/Zsd270QiC4Pjx4ygqKkq6RrP73qpVq5Rj6vWYnBDU0gRebjLjZZSN7M7KinApLy+3HWlkp/6wwIJAEnY1AmUnIzVOF/9ScOIjKCsrMzxn5+GIRCKYOnWq7rmePXtKWf9IJoogsLpaq56ga2xsxOLFix23QUZH4GR076VGoLfUhgxk3Cu7GoHXpPNR+AkLAknY1QgmTJiA888/X1r9XvgItA+H3vr66rR6L2ufPn0wY8aMFCFpJoC8RtkcpbCwMEkQmHU2eoLAre1exu+kXaTNCl5qBEaznvV8Mn5j10dglE9me7wou3v37rbzsCCQhF2NgIhSRsmyZhZ7FTVkZt6JRqOm5WjvTZBq8bZt2xIagdWQSr3O0+0iXjL2iHUiCIIYhYbBDKKnEQTZLs9m84ZEywByUBA48REYPQhhiRqyswCYkUagXgJC73gQPPfcc4hGoymdu7Jwmh56GoGy7LNTTjvtNFf5AWf3MYiOwm2dXpiGrJpmMk0jcHKvWSOQRFNTk2tBoIy4zWY7muG1RuBUQAGpGkEYRi122qAnCKyuKqrHsGHDPLkHo0ePTuuwDUIIh+H3NhuoBEEYNILmzZujW7du4RYERDSBiNYRUS0R3aJzfgwR7Seir+J/v7WaVzbRaNT2PALtgzBy5EhMmTLF0UjRDweY2YNrpBE4Kcsv7LTBC7u6F/dgzJgxGDlypO/1piNMv7dVjSCT5hF069YtsRyGnff/3//931FUVBReQUBEeQAeBnAhgAEAphPRAJ2kfxNCDI7/3WYzrzRkaASRSASnn366q5G3Xrl22+GUsI240mGnbbIjbWTGxac7piXXTUN2y/XSNKTFzbwFpbx097p///4p+UIrCAAMB1ArhKgTQjQAeBFAtQ95HeFkZnEYVEM7pNMIzPJoo4SC2C1Ji537r7dEhhuCXIoh101D6v9hMw2ZWQPOOuss07L0nOF69O7dWzefF8j41TsDUHvjtsSPaTmbiL4moveI6FSbeaXhxjQk4yUJ2jSU7rz2XBC7JWmRbRq66KKLPKvfKL+dUe6pp56KX/3qV6EwDelN0LOTX0YbZJXrFL26zd7dM8880/Ccer2udO+/+rzyDIVZI9D7hbStXQ6guxBiEIA/AnjTRt5YQqJriaiGiGqURdDsEo1GEY1Gbe9HYCQIvDAZyExvpxwjk1WmaQRWhGvz5s09q99OfqPjJSUlaN68eWDho1dccUVim0hZu/nZbYP2f9hMQ05/m/3791tup1YQAOGOGtoCQL1GbBcASdMWhRAHhBCH4p/fBVBARO2s5FWVMV8IUSWEqGrfvr2jhirS2OnDnQ0agV1ncRgWJ7Pa3nPPPTeUtne7gkDRWIMaBffr1y+x5lQYtJKg0RNEdrRqNUbzYfQ0r0zTCL4E0JuIKomoEMA0AG+pExBRJ4rfHSIaHq93t5W8MnEqCLxaLdTPEYxCOh+BnbLChtWRo98+Irv3VnnOnIwc7TJx4kTd407NoTKfl3QaQZcuXTB48GDdZWBkole32z1J7KYLvSAQQjQCmA3gAwBrALwshFhNRNcR0XXxZJcCWEVEXwN4CMA0EUM3r9s2GSFbEDh56N1oBBw1JCdtWIIFjBgyZAiA5OfDbAcuNxstlZeXm54Pi0agd6ykpATV1dUJv5Db99FNGjvovffpzE9eO4ulGADj5p53NcceU33+HwD/YzWvV7gVBLJ/iKA0Atkdq9fYGUEFbRo67bTTsHLlyqRjdjSCvn37JiK3rF53fn5+2vWUxo0bZ2vhPauRLV7g1EegUFBQYHl9KSujbLsagVWNPN016Q08Q6sRZBJhMA2pna9BCAKj82E2Dcl2FnvppNcbYdu5t+qoJ6v1WtEI9BaTO/fcc9PmCyKgQc8eH6Rfy48BoNUADhYEEgiDaWjXrl2Jz0FEhWSij0C2RuB352b13nbv3j3JZu/ElmwnTWFhYdq2BbnwnR+/k9N7J8NHkO46M8pHkEkogsDuMgReOYu98hF4aRqSPWHLSRuMsHptYRUEo0ePNlyl1KkpQsHps5uJGoHstOo0VjZusquR5+XlWdIIWBBIQrEb2nWuZZOPwOi8nhqql9bLNfKNkP1ie3kNQfhfnAoCs3xh8hHYbYedztKuIFD6DplRQ0b9kZ4g8IqcEgR79uwBYH+2pEzTkMz8QRBkx2AFo5Gv2gxidzvOIH/nAQPSL73lRiNIp61kkiDwY2DlhcZjRSNQvrNGIIFt27ahpKTEtiBwuzWlHebOneu6DCemIavmi7ALAqO06iWfichXE5cb/0vfvn0BuDcNOf3dwvB7q0fDo0aNwiWXXGIrv9u06vplOG21dVoR0uwslsiECRMwc+ZM2w+38kNZNSl06tTJdttk4qUgCALZL7aXAt3o3tq552qUZ069Ro2TcrwwDVVWVmLOnDlp67aLWd3q59evWe/qkbgToVtcXIxevXoZpjPSCMzaIZucEgRFRUXo2LGj7XzDhw/HiBEjcPbZZycdN/rxlOn5YcVN5x6GEaLbtH5fgxttSxEEZnHxVgSb3WgxK+cjkYgnaxGZaQRmAQF+mobsdMiRSAQjRozQLU85r4deHV4JAv9XlMpACgoKpG5g7zXpNAI7eTLJNERkvIGJH45Hs3bZOa7GiiCwUo6eQ9KtRmB0zkx7sYMfphGnpiE39SiflTlFRs5i7cq/7CzOUIISHm5GeW7LloFWa5OlEdhdw0fBbRRKGARB8+bNMWrUqLTp7GBUr9uly9MNPoLU6GRonHqCQC+PniBg01AIMfrBrdoTg1jZ06mJwG46pxARBg4c6LhOs073mmuuwbnnnmvLRxC0j0RPEOjNErZC165dk74b+S6Uc+kwEnqXXXYZpkyZ4qiN6nLV/61oBGE1DRmVp2hORs8jC4Icx8rUfzNkmob85vrrr08J77TatnQTyjp16oQxY8a4aZ4jZGgE6k5h4sSJ0kep6erX83sZOXPbtm1rukheOsy0Kr+cxeodyIwEgR1foDpfSUkJgJNhzGVlZawRZDNOXz4nnZXycLmp1wp+aARmx9LtSSy7fXZfPHX9ylaDbgRBq1atMGLECEybNi0pn9fapNK2/Px8/OpXv8KkSZMS57zeq8BMI5BRb9u2bW2lUden7CPcqVMnQ2GXrn3Dhg3DxIkTMWnSJFx++eWYPHmybjo/ncUsCDzES1u9lrKysiRhYJTGSMikM3OlS6emZ8+euPnmm9Oms9oOO52A3YlTXtKjRw/Tuq2O5M8//3yoN2NyYjMnopQRrJlpSE3z5s2THJp2V0e1SzqNwE4+2e0ZOHAgbr31VrRv396x7ygSiWDYsGGIRCLo37+/4ZpP7CzOcPr06QMg/chDeZCUDsMJgwcPBmCts5w9e7bh+vNuRlydO6duM51OKBmh1znJchb7TbpIE6ejO6eCoLy8HNdcc42jOq3WJ+P+62kECnbXypKBtj43+z/YwU/TEIePekBVVRVOO+00HDlyxFL6fv36YePGjY7qshOlIgO3Zefl5Znug+xWI3AbsWKlPVbTe9VWN79BRUVFUjlOggTMBJzbjspo0T0//AJW8Mofo80zfvz4pN9KScOCIIMgIjRr1syyIFBwMhFN1ixZmVFDZmmKiopM74tbwaZMcGrfvj3q6+sdlaHGzYuXLlxVliCw85s4vQ9WBYFbrrjiirRRQ25MbU6Q4Z+wm2/kyJEAgFmzZmHHjh2JMthHkOXcfPPNmD17tu18ei+ljBEJAJxyyim2yzFj7NixuOiii9K2w6yjS3dtnTt3xnXXXZc0k9Mtskw4WmRrL2a4FbBeCwL1WlBm9ftpGlK2DFXX7xVG5VdUVCS1gwVBBmJnlF1SUpI2IsZqHepjHTp0sF2mgt7G5m5eiNGjR6N58+amaWSYuvSWEfGr87DTYfqpEVgtywi9LRZlmiXN9h22Y8KyQrdu3SylmzRpEm699daUtijYCcWW6TvxAhYEIUDmbkdarrzySsM86Y6Z1ecVbn0EdtN5Sbp2K4Kgc+fOGDx4sOUOyo1pyCl6W6x64SNIV5aMqKG+ffvi0ksvTZuOiHxzDFsh9KYhIppAROuIqJaIbtE5/yMiWhH/+5yIBqnObSSilUT0FRHVyGhPLuFlx+m3I9qoDhk2Wqecc845jvOq26rXoSgvdVlZGaqrqy13OkSENm3aOG6L2TEj1NqLl79BOo1AVkeYTjM1wisfgRPNTCauBQER5QF4GMCFAAYAmE5E2t00NgA4VwhxOoDbAczXnB8rhBgshKhy255cQ5aPwC+cvBBBqdXV1dW29y0w+h2mTJmS4rdQRtlOHP6zZs1KRJX4YRqyqhHIRM8cFTROTUOy65aNDI1gOIBaIUSdEKIBwIsAqtUJhBCfCyH2xr/+H4AuEuoNPX6YMdI9mLI1AitY2VXLaTv8NA25XWJZ3cG3atUqZRFCp1ugEhGKi4uTJplZyWPlmBF6GoHMZ8Ysn5FG4GSyo166fv36WW2mZ2S8RgCgM4DNqu9b4seMuBrAe6rvAsCHRLSMiK41ykRE1xJRDRHVqMMCw4LdncVuuSXFguYIWS+jLI1izpw5OOOMMxzn13MMymibk3xuQ3PT1VlZWQng5KRAr+qRgZ5j2wsfgdHARi0IZF6vIlSdtM9uPYDcnc1kImMegV7rdK+WiMYiJgjU6+GOFEJsI6IOAD4iorVCiE9TChRiPuImpaqqqmBnlUigqKjI8kNRXV1teE49OpNtJnIiZNyOov3ySzRr1gwHDhwwTePWUZjOhNK2bVtHW5PKchbrCV0j9ExDfmHFHOOmTNn53A7EgkCGRrAFgHp92y4AtmkTEdHpAJ4EUC2E2K0cF0Jsi//fBeANxExNWYGsH1e9EqJZHbJHG+RBlIJbH4Gse3rllVfqLo2hxokg8NNX43afBDt1WPURuL1mo+dZWanTbL6BbE1BJrLKC7Np6EsAvYmokogKAUwD8JY6ARF1A/A6gBlCiG9Vx5sTUanyGcAFAFZJaFNGYNemafbiGXVAftrUjejbt6/lORLpTEN6cxuMyjH73qpVKwwfbj7mkKURyMaJRqBm0KBBhueMylLvEeGXs1hdX69evTBt2jTXS7S7aYP6PyC3U/ZK07CKa9OQEKKRiGYD+ABAHoCnhRCriei6+PnHAPwWQBmAR+IX0xiPEOoI4I34sXwALwgh3nfbpkzB7EG6+uqr8dRTTzkqV9YDI6sc9RLKTupUH+vbt6+UNhnVpUYRBF7NLJaFm05Ee9xoU6WioqKUPH76CAB5v72s32XYsGFYunSpZ+X7iZR5BEKId4UQfYQQvYQQv48feywuBCCEuEYI0SYeIpoIE41HGg2K/52q5GWALl2sBVY5GZ1pN36xk9/rh9wvH4EV9DQCs9E04I9pSOt4DGo0ma7Miy++2FX5dq7PTjq7aY3ylZWV4ec//7mn9emV4YV5iGcWe0hQI/N0nVHLli1x0003pa3DTr2//OUv8R//8R+22mZ0XuZLY1Zvunr0oobsTuTKZtLd00GDBiWWjnBTZpjwy9znNywIAkSJt3ezH4HTDtzuRKl0tGjRQkonqdd2szDO4uJi3bWFZKBoBOr1mvwYdVotV4ZG4CYCKUymrzARJq3WKiwIAqSyshJz585NuzCcm4fIiVrtZVSInXZYrVPZCEh2uYogsLNZfFjumdM2uDU7eOkjsJM3Xbqwdcx2fkM2DWUYfjxssjoevRcwCLuy3ktqphF4Oc1fz0fQqlUr1+W6JehOTIZGoHY+ZxJhDxxwCguCLEKvAw/7A6gwdepUTJ8+XfdcmJzFrVq1CiyE0Qi/TUNmaa3kv+CCCwz33rAzIAl6tzLAm4GYmzRO4R3KMhwvHNLqEZ/T9Vzsoo5T1yJjFzZZzmIiMl250k8h7MeEMi/K7NSpk27kmtt6g9LA/YZNQxmG3kPTvXt3z+uz2hn17NnTUjo1QYzCzNrmxjSU7lqcCCA/7o+bUXw6rLTfy3kEemXJ7nzd+Ajcmob8XrHUKiwIfOYnP/kJfvvb30orz41tX2/TGqOyZeFEBU7XIXvV+QY58pSNF9fil8YThvt9+umnA4ClcFi/osVkwqahAAjDgw0k28CdRBf5hRONwEoZTl4oK87uNm3aYO/evaEJH73xxhttl+2UIG3dXj6bP/jBDzB27Fjb8yIUrDw3QcKCIMNJZ/sO+gGTQSQSwdChQ7Fs2TLLeWRct5MyhBCYNWsWDh8+jD179khrixnpyrcT6WRlSWy/5hE41Qi8aFckEkGzZs2kl2sHdhZnKJnUCYeprXo28EmTJmHSpEnSygTSawROI0KKi4tRXFycEASySdeG8ePHo23btnj55ZdtlWV3SewwPTNq7Pg53BLEvBE2DTEpeKlyeuEMdNKedPMIwtAhRSIRRKPRUJjORo4cGUi9Tunbty/27t2bctyrtYZkasylpaUYN24c9u7di+XLlztuW9DPMDuLGQDeR4C4wau4bJkagd5KpWHxEVgpy8+82nzTpk3zfUlnBRkDm1GjRvmyBpWXzmIWBB4ShrhmJ21QwkrdrsfvFDtRQ26cxTIJ6l4FgV8zz53W46dpyGrZYdcI2DTEpDB16lTs37/f9baTsvDqJXGiERihCKsghH9QnYgX9fq9py+R/F34zAjrnsWsEWQ4Xji9CgoKbC205rQeq8hYa0iWecmoHKWNfpiGFII2Dcms0+yY0e/vdHJWWK7Zznk1bBrKMPx84IQQmDp1Krp37667m5QRVVVVXjfNNn6NeGW+UDKWwcgU/JroVVVVhaqqKowePTrpeNBmFDcYtf3EiRM+tySZcOj+jGPUD9Ypp5yCU045JcDW+I+Xar0TjYBNQ/IoKCjAD3/4Q8vp7bQnqHtm9Lxu3LgxbV6eWcw4Jswzhr3ESmfphUagV6a67qlTp4ZiKWsFp5PmnOYNI+n2A5FB2O+VFH2WiCYQ0ToiqiWiW3TOExE9FD+/goiGWM3LnMSLySt+h4jKeCGM9nN2ey3a0acTjSBd2oEDB6Jr164OW5hcbtAdsqzw0aA566yz8G//9m+Ol4/IBlwLAiLKA/AwgAsBDAAwnYgGaJJdCKB3/O9aAI/ayJuxyH7gp06d6nsbwjKXQM2Pf/xjzJo1C4C79mnztm7d2lI+vXvqp2lIS5gFgdV7KgOn2i8RuRbOdut0U0ZYncXDAdQKIeqEEA0AXgRQrUlTDeBZEeP/ALQmonKLeZk4bdu2TTnmRdRQ2CkqKkL79u1N03gVNWSEmWlINkq7xo8fj27duqGystJ1WXawo4nMmDEDZ5xxhu06vCZd23v16uVTS8KBDB9BZwCbVd+3ADjTQprOFvMCAIjoWsS0CXTr1s1di3OAc845Bw0NDRnVwdtBxujIyaY7bk1DMmnXrh1++tOfYs2aNbrnp0yZIjUaZdasWdi5cyc2bNhgOU9paSkuuugijBs3DgsWLMDu3btd35fi4mIA8Gw27y9+8QuUlpZ6UrYbwu4s1vtVtS01SmMlb+ygEPMBzAeAqqqq8NkrdAhyZvF5551nKX8m+giclO2mk7dCGKOGlDX0ZVFRUYGKigrU1dWZ1quH2a5udikvL8f06dNTNKEwD3rC3DZAjiDYAkBtYOsCYJvFNIUW8jIWCGIxuCAJatKQnQllmYDR9ShbSZaVldnO6wd9+vRxnJfIfIeyTHsXZCDDR/AlgN5EVElEhQCmAXhLk+YtADPj0UNnAdgvhNhuMS9jQi4+tICc65a5H7PZhDLZv5Efv3n37t0xc+ZMjBkzJuWc22ilXHxm013z5MmTLZcRStOQEKKRiGYD+ABAHoCnhRCriei6+PnHALwLYCKAWgBHAPzULK/bNuUS2RgVZAW7121lHoET81HPnj2xa9culJSUpJz3q8Pzqp50TuiwdeiZEDhh9L4pfo+gkDKhTAjxLmKdvfrYY6rPAsANVvNmC2F7Ucyw29YePXqgqKgI69at86yeFi1aGG5Go5QzdOhQW/Wb4eT36t+/P2bMmIHXX38dQOYJVp5Q5g0/+9nPUFtbi8WLFwPIjfBRJkCsPmCyoyCKioowatQoqWVq6dSpE/r27Wt4fs6cOYZLEGRzJxWWa5PZjo4dOwJA0jpZXuL1PezUqRNGjBiBHj164JJLLklbb9C/KS8xkcFYnRp/5ZVXJl40LZk2glWjXSbb7Fq8Mg2Znc9005BX6LV38uTJGDp0qKsJaE4nlDktJx2RSARXXXUVAODgwYMAnK+Y6jWsEXiI1z/uj370I0t19O7dGy1btjRN46StFRUVGDRoEC6++GLbecOAU2dxeXm55TK9QOZzFRbTUEFBAbp37y6tvLDBpiEma4lEIrj44ott7V0Q1ChZpiOxoqICp556qpTyMhm79zSM2mfQI3GFoNvBpqEMx+sHKIwvryzchI82a9ZM97gfpiEjIUdEuPrqqz2pU01Yw0ftlOv3PAIZ5igv33XWCDzE605aZix90COSMODkZdQKk3TLUHtJu3bt0LlzZ1t53LQtU5+ZTG23ApuGmBQy/aH2Cq9MQ2Eg6GvJ9sFDENcV9L1kQZAlZIoJJ+gHXo3MmcUyywh7ncp9s7s9ZyZoyF4h0zTEGgGThHrNFKcvQaYIELf4FT7qx+b1QUcNRaNRR3nDpEmEoQ1hggWBh/j5sLmtK9teDCvXo92MJNvugVc41QjCgl/zCGTXyc5ixhDuvJzTtWtX3HKLvd1Rg+hE0uG3wzesgiCT3wU7bWfTEJOEjFBFuw9VGJe7HjZsGCoqKkzXHTKqV72kgcwoLFnl6RF0hxfW8NEwtyEM12wGCwKXVFRUoKqqSvecHz++1ysuBr0qohVKS0sxa9asxBr6gLP7ErR67ha/RuhajeDyyy/3pV6/CKtWx87iEDNr1izDhc/8xKuH9/LLL09apyjMHWEYCEL4uwkYkOEs7t+/P84++2zb5cgmk5/NoNvOgiCDUUcNOSXd6KK0tBTDhw93VUcY8Gu0H+SEMr/qCauPwCphHfH7UYYRmflLZggcNZRZ9WSKacioDZkiCMJ8D4Mqj53FjCuCmkyUaYTtxZeJ0hYnHbObqKEw3QMg2Pakey/CGG2mhgVBBhNE1FA240YjCIP257dGEHTnlU2ws5hxhddRQ5lKLmpKmSII/Pxt+vTpg379+hnWz+9PDFeCgIjaEtFHRLQ+/r+NTpquRPQJEa0hotVE9HPVuf9HRFuJ6Kv430Q37QkbYRglho0wtzNTfARG+GUacrrEhNfotWf69Om44oorLKX1krDdKy1uNYJbACwWQvQGsDj+XUsjgF8KIfoDOAvADUQ0QHX+fiHE4PhfVm5i7xVE5Hokajd/2B9oN8i2l/ulJfhtqgl71JDT+zBo0CAAQF5enszmWCJo05DbjWmqAYyJf34GwBIAv1YnEEJsB7A9/vkgEa0B0BnANy7rDh3FxcVo1apVIHX73QmEHe398LrddvdL9qJuNg3FcPpbX3jhhRg/frwjQeDWWRw0bgVBx3hHDyHEdiIy3U2diHoAOAPAUtXh2UQ0E0ANYprDXpdtCoz//M//9L1OWR2c2YMqsxMN8wuRqaYhN6aabIoasoNe2yORSNKSI34StEaQVrcjor8Q0Sqdv2o7FRFRCwCvAbhRCHEgfvhRAL0ADEZMa7jXJP+1RFRDRDX19fV2qs5qgnopM0Uz8IswhC76vcREWAVBEKGaYQ8PTUdajUAIMd7oHBHtJKLyuDZQDmCXQboCxITA80KI11Vl71SleQLA2ybtmA9gPgBUVVXlRC90xRVXYP/+/YbnOXzUGDv3Iy8vD01NTa7KDfI+2u2YlfWjCgsLHdUXVmexQrY+017i1jT0FoCrANwZ/79Im4BiT8tTANYIIe7TnCtXTEsApgBY5bI9WYU27E0PP0xDMtIHjdl9ys/PR1NTU8Zdk4Ldjvm8885DmzZt0L9/f0f1hd1ZnImE3jSUhjsBnE9E6wGcH/8OIqogIiUCaCSAGQDO0wkT/QMRrSSiFQDGArjJZXtyFr86MSWywunDGMbONj/f+ngo6MlcetjtmAsKCjB8+HDXWqQ6vxIkoV4BNijC6OsJ43OvxpVGIITYDWCczvFtACbGP38GQPcuCCFmuKk/1/E7fPSMM85wbE7wGzsvXkFBAYCTI2tZZHv4qLq+4cOHo1WrVujbt2/a/EF3ikHXr0fQwot1uwzjl7/8pe5xtw9JtpuGzFA0gsbGxrRp/YrMsYPfNns9QUBE6NevX1Y9FzKReV/CaBpifEaregflGPOyXr+vqaSkBIB8jUDBrzkMftnsw+4sZuzj1lnMBIjMqCG/Xmo79fjVpksvvRRfffUVOnQwnQYTWvz+Da+44gosXbo0FP4Ap4RNiAXtLGZBkOEEpRH48SK5uTY77SstLcU555xjq9wwCTS/BUHXrl3RtWtXX+rygiCEQNgEjxY2DWUJYX/QGO9gU02MoqIi9OjRA5deemnQTTGksrJS93jQzmLWCDKYIBad85MwOtjC2NmGfaavEb/4xS+klkdEuOqqqyyn9YIRI0YYnps9ezZKS0td18GmIcYQP6KGZLw8dsrwyzTkFX6Hj2baBC8ZnWLYMPvNy8rKfGyJPTLryWFS8HtE78RGnk2E8bqbNWsGIByTuRhnsLOYcUwQaw317t0bZ555JkaNGuWoPjuEsdO1g1/tP/XUU9HU1ISBAwf6Ul+m4+XvkqnPLAuCDMdv23ckEsGECRMsl9u8eXOnTcoI05BZG/3S1ogosfSHUwYMGJA+EZMWL39zdhYzhrh1FHbq1Anr16/3xF47Z86clHYFNWKSVW8YZxa75Te/+Y2t9ZayibD8Nn75zoxgH0GOM2bMGMyaNQvl5eXSy87Pz3e17V8QL6ne/rbZTmFhYcY5mhm58K+fwajDR512mpFIBBUVFaZpwhxiaoRTTSTd0t9hGUEyzgnjbxi0s5gFAcMwTI7DgiDDybTJRLnoI2CYsJObHqIsIVs7JWUDcTcRR27uzSWXXOLZSqQMo0fQpiEWBBlOpmkEVujWrRuqq6sDC2k87bTTpJSTib4VJjdh01CG079/fxQUFKCqqiropjhGG1lERBg8eHAod0MzErjK7F5ltzMreZhgCOPvwRoB4xgiQsuWLfFf//VfQTfFMnoP/A033BBAS+Qyfvx4VxvCM7mN3gDCT1gjYAKnTZs2ntfhtbO4oKAAZ511VihHm0z4adGiBWbMCG4Ld1eCgIjaEtFHRLQ+/l/3jSaijUS0koi+IqIau/kZxi5ed8jc4TOy6dmzp+n5MM8juAXAYiFEbwCL49+NGCuEGCyEUBuz7eRnmMAJUgDw6qJyYCGeilsfQTWAMfHPzwBYAuDXPuZnMoxMn0cQJDfccAOOHz8edDMykv79+2PNmjWJ75kY0RVmjaCjEGI7AMT/G+3+LQB8SETLiOhaB/lBRNcSUQ0R1dTX17tsNhMGgnaQeY3sF7ZZs2Zo1aqV1DJzhcsvvzyxMYwXHWmmDzTSagRE9BcAnXROzbFRz0ghxDYi6gDgIyJaK4T41EZ+CCHmA5gPAFVVVZknzrMA2Q/79ddfj++//15qmUZ49aJa6VQyvZPIRGbMmIGtW7cmHfPyd6iqqkJ9fT1Gjx7tWR1eklYQCCHGG50jop1EVC6E2E5E5QB2GZSxLf5/FxG9AWA4gE8BWMrPhAPZI6nWrVujdevWUstkGCDmeE3nfAXkCYfCwkJUV1dLKcuIMJuG3gKg7BZ9FYBF2gRE1JyISpXPAC4AsMpqfia7yCUfQefOndGyZUuMHTvW97oZxg5uncV3AniZiK4GsAnAZQBARBUAnhRCTATQEcAb8RcxH8ALQoj3zfJnG507dw66CVJgE4c9ioqKcNNNNwXdDCZLCO0OZUKI3QDG6RzfBmBi/HMdAN199IzyZxM333xzKJdKYNyhOB7ZtJXZhG1w069fP3ToYBgzA4CXmMhISkpKgm4C4wHDhg1Dx44d0b1796CbwjigtLQUI0eOdL3Xs2yC2iGPl5hg0iJzBJItPgIiYiFgk969ewMAiouLA22HEAJEhPHjx6N9+/aBtsUOvOgcwzAZzwUXXIARI0YEpiWHzQwUJlgjYHIC7gSCJxKJoGXLlkE3I2Px8hlmQcAwDJNBhHEeAcPYwq+ROWsADGMdFgRMTsCCgcl0iouL0bdvX1d7eRvBzmImLco2jBwKyzDB0a5dO0ybNs2TslkQMGkZOHAgGhoaQhdzbQe3GsGMGTNQW1srqTVMkGTiEtRew4KASQsRYejQodLKykSsLmLGhJdMffb8gH0EDMMwOQ4LAoZhmByHBQHjK9myxATDZBMsCBiGYXIcFgRMVqLVAFgjYBhjWBAwgaDMTWAYJng4fJTxnYsuusj3JZxZI2AYY1gQZCCTJ0/GmjVrgm6GY84444ygm8DkIF6u55/psCDIQIYMGYIhQ4YE3QyGYbIEVz4CImpLRB8R0fr4/zY6afoS0VeqvwNEdGP83P8joq2qcxPdtIdhjGDTEMMY49ZZfAuAxUKI3gAWx78nIYRYJ4QYLIQYDGAogCMA3lAluV85L4R412V7GEaX/HxWfhnGCLeCoBrAM/HPzwC4OE36cQC+E0L8y2W9DGOJ0tJSnHPOORgxYkTQTWGY0OJWEHQUQmwHgPj/DmnSTwOwUHNsNhGtIKKn9UxLCkR0LRHVEFFNfX29u1YzOUN+fj7OO+88FBQUBN0UhgktaQUBEf2FiFbp/FXbqYiICgFcBOAV1eFHAfQCMBjAdgD3GuUXQswXQlQJIarat29vp2qGYRjGhLSGUyHEeKNzRLSTiMqFENuJqBzALpOiLgSwXAixU1V24jMRPQHgbWvNZhhzWrRoAQA4++yzA24Jw4Qftx60twBcBeDO+P9FJmmnQ2MWUoRI/OsUAKtctodhAACFhYWYO3du0M1gQgjPI0jFrY/gTgDnE9F6AOfHv4OIKogoEQFERCXx869r8v+BiFYS0QoAYwHc5LI9DMMwuih+Ig4lTsWVRiCE2I1YJJD2+DYAE1XfjwAo00k3w039DMMwVrnsssuwfPlydOzYMeimhA4OrmYYJido2bIlxowZE3QzQgmvPsowDJPjsCBgGIbJcVgQMAzD5DgsCBiGYXIcFgQMwzA5DgsChmGYHIcFAcMwTI7DgoBhGCbHoUxcd4OI6gE43dOgHYDvJTYnE+Brzg34mnMDN9fcXQiRsnxzRgoCNxBRjRCiKuh2+Alfc27A15wbeHHNbBpiGIbJcVgQMAzD5Di5KAjmB92AAOBrzg34mnMD6deccz4ChmEYJplc1AgYhmEYFSwIGIZhcpycEQRENIGI1hFRLRHdEnR7ZEFEXYnoEyJaQ0Sriejn8eNtiegjIlof/99Glec38fuwjoh+EFzr3UFEeUT0TyJ6O/49q6+ZiFoT0atEtDb+e5+dA9d8U/y5XkVEC4moWbZdMxE9TUS7iGiV6pjtaySiofGtf2uJ6CGysyenECLr/wDkAfgOQE8AhQC+BjAg6HZJurZyAEPin0sBfAtgAIA/ALglfvwWAHfFPw+IX38RgMr4fckL+jocXvsvALwA4O3496y+ZgDPALgm/rkQQOtsvmYAnQFsAFAc//4ygJ9k2zUDGA1gCIBVqmO2rxHAFwDOBkAA3gNwodU25IpGMBxArRCiTgjRAOBFANUBt0kKQojtQojl8c8HAaxB7AWqRqzjQPz/xfHP1QBeFEIcF0JsAFCL2P3JKIioC4AfAnhSdThrr5mIWiLWYTwFAEKIBiHEPmTxNcfJB1BMRPkASgBsQ5ZdsxDiUwB7NIdtXSMRlQNoKYT4h4hJhWdVedKSK4KgM4DNqu9b4seyCiLqAeAMAEsBdBRCbAdiwgJAh3iybLkXDwD4TwBR1bFsvuaeAOoBLIibw54koubI4msWQmwFcA+ATQC2A9gvhPgQWXzNKuxeY+f4Z+1xS+SKINCzlWVV3CwRtQDwGoAbhRAHzJLqHMuoe0FEkwDsEkIss5pF51hGXTNiI+MhAB4VQpwB4DBiJgMjMv6a43bxasRMIBUAmhPRj82y6BzLqGu2gNE1urr2XBEEWwB0VX3vgpiKmRUQUQFiQuB5IcTr8cM74+oi4v93xY9nw70YCeAiItqImJnvPCJ6Dtl9zVsAbBFCLI1/fxUxwZDN1zwewAYhRL0Q4gSA1wGMQHZfs4Lda9wS/6w9bolcEQRfAuhNRJVEVAhgGoC3Am6TFOKRAU8BWCOEuE916i0AV8U/XwVgker4NCIqIqJKAL0RczJlDEKI3wghuggheiD2W34shPgxsvuadwDYTER944fGAfgGWXzNiJmEziKikvhzPg4xH1g2X7OCrWuMm48OEtFZ8Xs1U5UnPUF7zH30zE9ELKLmOwBzgm6PxOsahZgKuALAV/G/iQDKACwGsD7+v60qz5z4fVgHG5EFYfwDMAYno4ay+poBDAZQE/+t3wTQJgeueR6AtQBWAfgTYtEyWXXNABYi5gM5gdjI/mon1wigKn6fvgPwP4ivHGHlj5eYYBiGyXFyxTTEMAzDGMCCgGEYJsdhQcAwDJPjsCBgGIbJcVgQMAzD5DgsCBiGYXIcFgQMwzA5zv8HQ7g7vEYaJDcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_vec = np.arange(0, epochs)\n",
    "plt.plot(t_vec[1:], FVU_validation[1:])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(t_vec[1:], SB_M1[1:], color='0.5', label=\"Method 1\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
