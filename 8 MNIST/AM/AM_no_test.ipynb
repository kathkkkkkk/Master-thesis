{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_orig, y_train_orig), (x_valid_orig, y_valid_orig) = mnist.load_data()\n",
    "\n",
    "x_test_orig, y_test_orig = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of data \n",
    "def data_format(y): \n",
    "    y_10 = []\n",
    "    for i in np.arange(10): \n",
    "        temp = (y==i).astype(int)\n",
    "        y_10 = np.append(y_10, temp)\n",
    "        #print(y_10)\n",
    "    y_10 = y_10.reshape(y.shape[0], -1, order='F')\n",
    "    return y_10 \n",
    "\n",
    "# normalize data \n",
    "x_train = x_train_orig.reshape(x_train_orig.shape[0], -1).astype('float32')/255.\n",
    "y_train = data_format(y_train_orig)\n",
    "\n",
    "x_valid = x_valid_orig.reshape(x_valid_orig.shape[0], -1).astype('float32')/255.\n",
    "y_valid = data_format(y_valid_orig)\n",
    "\n",
    "#x_test = x_test_orig.reshape(x_test_orig.shape[0], -1).astype('float32')/255.\n",
    "#y_test = data_format(y_test_orig)\n",
    "x_test = x_test_orig\n",
    "y_test = y_test_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimization function \n",
    "def min_fun(x, y, w, lambda_): \n",
    "    N = np.shape(x)[0]\n",
    "    K = np.shape(w)[0]\n",
    "    I = np.identity(K)\n",
    "    one = np.ones(N)\n",
    "    x_ = np.c_[x, one]\n",
    "    S = np.cos(x_.dot(w.T)) \n",
    "    beta = np.linalg.inv(np.dot(S.T, S) + lambda_ * N * I).dot(S.T).dot(y)\n",
    "    return beta, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_compute(y, pred):\n",
    "    #error = - np.sum(np.diagonal(y.dot(np.log(pred+1e-10).T)))\n",
    "    error = np.mean(np.sum((y-pred)**2, axis=1))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_compute(y, pred): \n",
    "    y_index = np.argmax(y, 1)\n",
    "    pred_index = np.argmax(pred, 1)\n",
    "    accuracy = np.mean((pred_index==y_index).astype('int'))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metropolis algorithm 1\n",
    "#def algorithm_1(x_train, y_train, x_test, y_test, x_validation, y_validation, K, M, lambda_, delta, gamma):\n",
    "def algorithm_1(x_train, y_train, x_valid, y_valid, x_test, y_test, K, M, lambda_, delta, gamma):\n",
    "    \n",
    "    # normalize the data \n",
    "    #x_mean = np.mean(x_train)\n",
    "    #x_std = np.std(x_train, ddof=1)\n",
    "    #y_mean = np.mean(y_train)\n",
    "    #y_std = np.std(y_train, ddof=1)\n",
    "    \n",
    "    #x_train_norm = (x_train - x_mean)/x_std\n",
    "    #y_train_norm = (y_train - y_mean)/y_std\n",
    "    #x_test_norm = (x_test - x_mean)/x_std\n",
    "    #y_test_norm = (y_test - y_mean)/y_std\n",
    "    #x_validation_norm = (x_validation - x_mean)/x_std\n",
    "    #y_validation_norm = (y_validation - y_mean)/y_std\n",
    "    \n",
    "    N = np.shape(x_train)[0]\n",
    "    d = np.shape(x_train)[1] \n",
    "    w = np.zeros(K*(d+1)).reshape((K, d+1)) #? \n",
    "    \n",
    "    error_train_list = []\n",
    "    error_valid_list = []\n",
    "    error_test_list = []\n",
    "    \n",
    "    accuracy_train_list = []\n",
    "    accuracy_valid_list = []\n",
    "    accuracy_test_list = []\n",
    "  \n",
    "    #beta, S = min_fun(x_train_norm, y_train_norm, w, lambda_)\n",
    "    beta = np.zeros(10*K).reshape(10, K)\n",
    "    S = np.zeros(10*N*K).reshape(10, N, K)\n",
    "    for i in np.arange(10): \n",
    "        beta[i],  S[i] = min_fun(x_train, y_train[:,i], w, lambda_)\n",
    "    #print(beta)\n",
    "    \n",
    "    \n",
    "    for epoch in range(M): \n",
    "        #print('w=', i)\n",
    "        r_n = np.random.normal(0, 1, K*(d+1)).reshape((K, d+1))\n",
    "        w_temp = w + delta * r_n\n",
    "        #print(w_temp)\n",
    "        #beta_temp, S_temp = min_fun(x_train_norm, y_train_norm, w_temp, lambda_)\n",
    "        beta_temp = np.zeros(10*K).reshape(10, K)\n",
    "        S_temp = np.zeros(10*N*K).reshape(10, N, K)\n",
    "        for i in np.arange(10): \n",
    "            beta_temp[i],  S_temp[i] = min_fun(x_train, y_train[:,i], w_temp, lambda_)\n",
    "        #print(beta_temp)\n",
    "        \n",
    "        for k in range(K): \n",
    "            #print('k=', k)\n",
    "            r_u = np.random.uniform(0, 1)\n",
    "            #print(np.linalg.norm(beta_temp[:,k], ord=2))\n",
    "            #print(np.linalg.norm(beta[:,k], ord=2))\n",
    "            #print(r_u)\n",
    "            #print((np.linalg.norm(beta_temp[:,k], ord=2)/np.linalg.norm(beta[:,k], ord=2))**gamma)\n",
    "            \n",
    "            if (np.linalg.norm(beta_temp[:,k], ord=2)\n",
    "                /np.linalg.norm(beta[:,k], ord=2))**gamma > r_u: \n",
    "                #print('yes')\n",
    "                w[k] = w_temp[k]\n",
    "                #print('w_k', w[k])\n",
    "                beta[:,k] = beta_temp[:,k]\n",
    "                #print('beta_k', beta[k])\n",
    "                \n",
    "        #beta, S = min_fun(x_train_norm, y_train_norm, w, lambda_)\n",
    "        beta = np.zeros(10*K).reshape(10, K)\n",
    "        S = np.zeros(10*N*K).reshape(10, N, K)\n",
    "        for i in np.arange(10): \n",
    "            beta[i],  S[i] = min_fun(x_train, y_train[:,i], w, lambda_)\n",
    "        \n",
    "        #f_est_train = S.dot(beta) * y_std + y_mean\n",
    "        pred_train = np.zeros(10*N).reshape(N, 10)\n",
    "        for i in np.arange(10): \n",
    "            pred_train[:,i] = S[i].dot(beta[i])\n",
    "        error_train = error_compute(y_train, pred_train)\n",
    "        error_train_list = np.append(error_train_list, error_train)\n",
    "        accuracy_train = accuracy_compute(y_train, pred_train)\n",
    "        accuracy_train_list = np.append(accuracy_train_list, accuracy_train)\n",
    "        \n",
    "        #beta_validation, S_validation = min_fun(x_valid, y_valid, w, lambda_)\n",
    "        #f_est_validation = S_validation.dot(beta) * y_std + y_mean\n",
    "        N_valid = np.shape(x_valid)[0]\n",
    "        beta_valid = np.zeros(10*K).reshape(10, K)\n",
    "        S_valid = np.zeros(10*N_valid*K).reshape(10, N_valid, K)\n",
    "        for i in np.arange(10): \n",
    "            beta_valid[i],  S_valid[i] = min_fun(x_valid, y_valid[:,i], w, lambda_)\n",
    "        pred_valid = np.zeros(10*N_valid).reshape(N_valid, 10)\n",
    "        for i in np.arange(10): \n",
    "            pred_valid[:,i] = S_valid[i].dot(beta[i])\n",
    "        error_valid= error_compute(y_valid, pred_valid)\n",
    "        error_valid_list = np.append(error_valid_list, error_valid)\n",
    "        accuracy_valid= accuracy_compute(y_valid, pred_valid)\n",
    "        accuracy_valid_list = np.append(accuracy_valid_list, accuracy_valid)\n",
    "        \n",
    "        #beta_test, S_test = min_fun(x_test_norm, y_test_norm, w, lambda_)\n",
    "        #f_est_test = S_test.dot(beta) * y_std + y_mean\n",
    "        #N_test = np.shape(x_test)[0]\n",
    "        #beta_test = np.zeros(10*K).reshape(10, K)\n",
    "        #S_test = np.zeros(10*N_test*K).reshape(10, N_test, K)\n",
    "        #for i in np.arange(10): \n",
    "            #beta_test[i],  S_test[i] = min_fun(x_test, y_test[:,i], w, lambda_)\n",
    "        #pred_test = np.zeros(10*N_test).reshape(N_test, 10)\n",
    "        #for i in np.arange(10): \n",
    "            #pred_test[:,i] = S_test[i].dot(beta[i])\n",
    "        #error_test = error_compute(y_test, pred_test)\n",
    "        #error_test_list = np.append(error_test_list, error_test)\n",
    "        #accuracy_test = accuracy_compute(y_test, pred_test)\n",
    "        #accuracy_test_list = np.append(accuracy_test_list, accuracy_test)\n",
    "        pred_test = []\n",
    "    \n",
    "        # Print the training loss for every epoch\n",
    "        print(\"\\nEnd of epoch  \" + str(epoch) + \", Training error \" + str(error_train) + \",Accuracy \" + str(accuracy_train)) \n",
    "        print(\"\\nEnd of epoch  \" + str(epoch) + \", Validation error \" + str(error_valid) + \", Validation accuracy \" + str(accuracy_valid))\n",
    "        \n",
    "    #error_valid_min = np.min(error_validation_list)\n",
    "    \n",
    "    #error_test_end = error_compute(y_test_norm, S_test, beta_test)\n",
    "        \n",
    "    #return beta, w, f_est_train, f_est_validation, error_train_list, error_validation_list, error_test_list,error_valid_min, error_test_end\n",
    "    return beta, w, pred_train, pred_valid, pred_test, error_train_list, error_valid_list, error_test_list, accuracy_train_list, accuracy_valid_list, accuracy_test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "              M = 100, K = 2**5, lambda_ = 0.1, delta = 0.1, gamma = 1): \n",
    "    beta, w, pred_train, pred_valid, pred_test, error_train_list, error_valid_list, error_test_list, accuracy_train_list, accuracy_valid_list, accuracy_test_list = algorithm_1(\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test, K, M, lambda_, delta, gamma)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    epoch_list = np.arange(1, 101)\n",
    "    plt.subplot(1, 2,  1)\n",
    "    plt.semilogy(epoch_list, error_train_list, label = 'training_loss')\n",
    "    plt.semilogy(epoch_list, error_valid_list, label = 'validation_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epoch_list, accuracy_train_list*100, label = 'accuracy_loss')\n",
    "    plt.plot(epoch_list, accuracy_valid_list*100, label = 'accuracy_loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('%')\n",
    "    plt.title('Accuracy')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
