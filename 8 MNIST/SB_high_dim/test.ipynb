{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([1,2,3]).reshape((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1 -2]\n",
      " [ 1  0 -1]\n",
      " [ 2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "temp3 = temp - temp.T\n",
    "print(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [-1  0  1]\n",
      " [-2 -1  0]]\n",
      "[[1.         0.84147098 0.45464871]\n",
      " [0.84147098 1.         0.84147098]\n",
      " [0.45464871 0.84147098 1.        ]]\n",
      "[[ 0.          0.84147098  0.90929743]\n",
      " [-0.84147098  0.          0.84147098]\n",
      " [-0.90929743 -0.84147098  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "diff = temp.T - temp\n",
    "print(diff)\n",
    "snc = np.sinc(1 * diff / np.pi)\n",
    "print(snc)\n",
    "print(diff*snc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n",
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "temp1 = np.tile(temp, (3, 1))\n",
    "temp2 = np.tile(temp.T, (3, 1))\n",
    "print(temp1)\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4096      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 438ms/step - loss: 4.9870 - accuracy: 0.0000e+00 - val_loss: 6.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5.3454 - accuracy: 0.0000e+00 - val_loss: 4.9835 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 5.7329 - accuracy: 0.0000e+00 - val_loss: 7.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 6.1517 - accuracy: 0.0000e+00 - val_loss: 5.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6.6045 - accuracy: 0.0000e+00 - val_loss: 8.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 7.0940 - accuracy: 0.0000e+00 - val_loss: 6.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.6231 - accuracy: 0.0000e+00 - val_loss: 9.1870 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 8.1952 - accuracy: 0.0000e+00 - val_loss: 7.8550 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.8136 - accuracy: 0.0000e+00 - val_loss: 10.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 9.4821 - accuracy: 0.0000e+00 - val_loss: 9.1647 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 10.2048 - accuracy: 0.0000e+00 - val_loss: 12.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 10.9861 - accuracy: 0.0000e+00 - val_loss: 10.7024 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 11.8307 - accuracy: 0.0000e+00 - val_loss: 13.9843 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 12.7437 - accuracy: 0.0000e+00 - val_loss: 12.5071 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 13.7307 - accuracy: 0.0000e+00 - val_loss: 16.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.7977 - accuracy: 0.0000e+00 - val_loss: 14.6243 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 15.9511 - accuracy: 0.0000e+00 - val_loss: 18.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 17.1981 - accuracy: 0.0000e+00 - val_loss: 17.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 18.5460 - accuracy: 0.0000e+00 - val_loss: 21.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 20.0031 - accuracy: 0.0000e+00 - val_loss: 20.0188 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 21.5783 - accuracy: 0.0000e+00 - val_loss: 24.9566 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 23.2812 - accuracy: 0.0000e+00 - val_loss: 23.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 25.1219 - accuracy: 0.0000e+00 - val_loss: 28.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 27.1118 - accuracy: 0.0000e+00 - val_loss: 27.4308 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 29.2629 - accuracy: 0.0000e+00 - val_loss: 33.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 31.5881 - accuracy: 0.0000e+00 - val_loss: 32.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.1017 - accuracy: 0.0000e+00 - val_loss: 38.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 36.8189 - accuracy: 0.0000e+00 - val_loss: 37.6045 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 39.7561 - accuracy: 0.0000e+00 - val_loss: 45.1968 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 42.9311 - accuracy: 0.0000e+00 - val_loss: 44.0318 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 46.3633 - accuracy: 0.0000e+00 - val_loss: 52.5166 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 50.0732 - accuracy: 0.0000e+00 - val_loss: 51.5572 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 54.0834 - accuracy: 0.0000e+00 - val_loss: 61.0535 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 58.4183 - accuracy: 0.0000e+00 - val_loss: 60.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 63.1039 - accuracy: 0.0000e+00 - val_loss: 71.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 68.1687 - accuracy: 0.0000e+00 - val_loss: 70.6776 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 73.6433 - accuracy: 0.0000e+00 - val_loss: 82.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 79.5607 - accuracy: 0.0000e+00 - val_loss: 82.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 85.9568 - accuracy: 0.0000e+00 - val_loss: 96.1753 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 92.8700 - accuracy: 0.0000e+00 - val_loss: 96.8606 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 100.3422 - accuracy: 0.0000e+00 - val_loss: 111.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 108.4184 - accuracy: 0.0000e+00 - val_loss: 113.3748 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 117.1472 - accuracy: 0.0000e+00 - val_loss: 130.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 126.5813 - accuracy: 0.0000e+00 - val_loss: 132.6898 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 136.7773 - accuracy: 0.0000e+00 - val_loss: 151.9405 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 147.7967 - accuracy: 0.0000e+00 - val_loss: 155.2764 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 159.7055 - accuracy: 0.0000e+00 - val_loss: 177.0427 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 172.5753 - accuracy: 0.0000e+00 - val_loss: 181.6838 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 186.4833 - accuracy: 0.0000e+00 - val_loss: 206.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 201.5125 - accuracy: 0.0000e+00 - val_loss: 212.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 217.7532 - accuracy: 0.0000e+00 - val_loss: 240.4924 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 235.3021 - accuracy: 0.0000e+00 - val_loss: 248.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 254.2641 - accuracy: 0.0000e+00 - val_loss: 280.3450 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 274.7518 - accuracy: 0.0000e+00 - val_loss: 290.7785 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 296.8873 - accuracy: 0.0000e+00 - val_loss: 326.8282 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 320.8017 - accuracy: 0.0000e+00 - val_loss: 340.0160 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 346.6371 - accuracy: 0.0000e+00 - val_loss: 381.0376 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 374.5456 - accuracy: 0.0000e+00 - val_loss: 397.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 404.6922 - accuracy: 0.0000e+00 - val_loss: 444.2457 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 437.2537 - accuracy: 0.0000e+00 - val_loss: 464.6422 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 472.4218 - accuracy: 0.0000e+00 - val_loss: 517.9298 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 510.4011 - accuracy: 0.0000e+00 - val_loss: 542.9806 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 551.4139 - accuracy: 0.0000e+00 - val_loss: 603.8019 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 595.6974 - accuracy: 0.0000e+00 - val_loss: 634.3662 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 643.5087 - accuracy: 0.0000e+00 - val_loss: 703.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 695.1221 - accuracy: 0.0000e+00 - val_loss: 740.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 750.8347 - accuracy: 0.0000e+00 - val_loss: 820.3468 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 810.9625 - accuracy: 0.0000e+00 - val_loss: 865.1037 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 875.8486 - accuracy: 0.0000e+00 - val_loss: 955.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 945.8566 - accuracy: 0.0000e+00 - val_loss: 1009.7330 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1021.3807 - accuracy: 0.0000e+00 - val_loss: 1113.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1102.8385 - accuracy: 0.0000e+00 - val_loss: 1178.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1190.6816 - accuracy: 0.0000e+00 - val_loss: 1297.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1285.3875 - accuracy: 0.0000e+00 - val_loss: 1373.7897 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1387.4720 - accuracy: 0.0000e+00 - val_loss: 1510.0162 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1497.4784 - accuracy: 0.0000e+00 - val_loss: 1601.1692 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1615.9929 - accuracy: 0.0000e+00 - val_loss: 1757.1010 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 1743.6305 - accuracy: 0.0000e+00 - val_loss: 1864.9993 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1881.0535 - accuracy: 0.0000e+00 - val_loss: 2043.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2028.9524 - accuracy: 0.0000e+00 - val_loss: 2170.6926 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2188.0696 - accuracy: 0.0000e+00 - val_loss: 2374.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2359.1741 - accuracy: 0.0000e+00 - val_loss: 2524.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 2543.0908 - accuracy: 0.0000e+00 - val_loss: 2757.3621 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2740.6648 - accuracy: 0.0000e+00 - val_loss: 2932.4966 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2952.8008 - accuracy: 0.0000e+00 - val_loss: 3198.3562 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3180.4136 - accuracy: 0.0000e+00 - val_loss: 3402.5742 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 3424.4771 - accuracy: 0.0000e+00 - val_loss: 3705.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3685.9602 - accuracy: 0.0000e+00 - val_loss: 3942.3071 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3965.8860 - accuracy: 0.0000e+00 - val_loss: 4286.0166 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4265.2480 - accuracy: 0.0000e+00 - val_loss: 4559.7686 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 4585.0830 - accuracy: 0.0000e+00 - val_loss: 4948.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4926.3594 - accuracy: 0.0000e+00 - val_loss: 5262.9946 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5290.0688 - accuracy: 0.0000e+00 - val_loss: 5701.2939 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 5677.0791 - accuracy: 0.0000e+00 - val_loss: 6059.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 6088.2402 - accuracy: 0.0000e+00 - val_loss: 6550.4849 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6524.2007 - accuracy: 0.0000e+00 - val_loss: 6955.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 6985.5342 - accuracy: 0.0000e+00 - val_loss: 7501.1812 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7472.4951 - accuracy: 0.0000e+00 - val_loss: 7953.3350 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7985.1670 - accuracy: 0.0000e+00 - val_loss: 8554.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 8523.1611 - accuracy: 0.0000e+00 - val_loss: 9052.9639 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "from GenerateData import getDataset_highDim\n",
    "from neural_network import NN_define\n",
    "from method_2_high_dim import method_2_w0, method_2\n",
    "\n",
    "N_train = 20\n",
    "N_test = 10\n",
    "d = 3\n",
    "\n",
    "# import data\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = getDataset_highDim(N_train=N_train, N_test=N_test, d=d)\n",
    "        \n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "K = 2**10\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = NN_define(input_size = d, m_size = K, output_size = 1)\n",
    "model.compile(loss='mse', \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=x_train, y=y_train, \n",
    "          validation_data = (x_valid, y_valid), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size)\n",
    "pred_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n",
      "[[95.02185 ]\n",
      " [95.20201 ]\n",
      " [95.13088 ]\n",
      " [94.2831  ]\n",
      " [94.67556 ]\n",
      " [95.33351 ]\n",
      " [95.2086  ]\n",
      " [94.83574 ]\n",
      " [95.35751 ]\n",
      " [94.42533 ]\n",
      " [95.06394 ]\n",
      " [94.742516]\n",
      " [94.932   ]\n",
      " [95.33333 ]\n",
      " [94.95743 ]\n",
      " [95.20509 ]\n",
      " [95.27781 ]\n",
      " [94.47012 ]\n",
      " [95.30675 ]\n",
      " [95.10079 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train))\n",
    "print(pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_valid = model.preditc(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95.32297 ],\n",
       "       [94.89007 ],\n",
       "       [95.153854],\n",
       "       [94.3416  ],\n",
       "       [95.194626],\n",
       "       [95.01727 ],\n",
       "       [94.917244],\n",
       "       [94.99806 ],\n",
       "       [95.28735 ],\n",
       "       [94.67064 ],\n",
       "       [94.94661 ],\n",
       "       [95.05948 ],\n",
       "       [94.36626 ],\n",
       "       [95.24048 ],\n",
       "       [95.23312 ],\n",
       "       [95.06507 ],\n",
       "       [94.78723 ],\n",
       "       [94.90286 ],\n",
       "       [95.109535],\n",
       "       [95.38812 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.68138826],\n",
       "       [ 2.0240035 ],\n",
       "       [ 4.825358  ],\n",
       "       [ 4.2098765 ],\n",
       "       [57.68716   ],\n",
       "       [67.58807   ],\n",
       "       [ 6.7628126 ],\n",
       "       [ 3.1865368 ],\n",
       "       [ 0.49984813],\n",
       "       [-1.1722863 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5       ]\n",
      " [ 0.        ]\n",
      " [ 0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([1,2,3]).reshape((3,1))\n",
    "px = np.array([4,5,6]).reshape((3,1))\n",
    "fp = np.sqrt(px) * (y - np.mean(y)) / px\n",
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-5dd6e688334f>:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  px_train = (np.exp(-1 / 2 * np.sum(np.multiply(x_train.T, cov_x @ x_train.T), axis=0)) * 1 / (\n",
      "<ipython-input-39-5dd6e688334f>:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  px_train = (np.exp(-1 / 2 * np.sum(np.multiply(x_train.T, cov_x @ x_train.T), axis=0)) * 1 / (\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([1,2,3,4,5,6,7,8,9,10]).reshape((5,2))\n",
    "cov_x = np.cov(x_train.T)\n",
    "px_train = (np.exp(-1 / 2 * np.sum(np.multiply(x_train.T, cov_x @ x_train.T), axis=0)) * 1 / (\n",
    "                                (2 * np.pi) ** (d / 2)) / np.sqrt(np.linalg.det(cov_x))).reshape(len(x_train), 1)\n",
    "print(np.shape(px_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
