{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data \n",
    "DATASET_SIZE = 70000\n",
    "TRAIN_RATIO = 0.7\n",
    "VALIDATION_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x = np.concatenate([x_train, x_test])\n",
    "y = np.concatenate([y_train, y_test])\n",
    "\n",
    "x_train_orig, x_valid_orig, y_train_orig, y_valid_orig = train_test_split(x, y, test_size=(1-TRAIN_RATIO))\n",
    "x_valid_orig, x_test_orig, y_valid_orig, y_test_orig = train_test_split(x_valid_orig, y_valid_orig, test_size=((TEST_RATIO/(VALIDATION_RATIO+TEST_RATIO))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the format of data \n",
    "def data_format(y): \n",
    "    y_10 = []\n",
    "    for i in np.arange(10): \n",
    "        temp = (y==i).astype(int)\n",
    "        y_10 = np.append(y_10, temp)\n",
    "        #print(y_10)\n",
    "    y_10 = y_10.reshape(y.shape[0], -1, order='F')\n",
    "    return y_10 \n",
    "\n",
    "# normalize data \n",
    "x_train = x_train_orig.reshape(x_train_orig.shape[0], -1).astype('float32')/255.\n",
    "y_train = data_format(y_train_orig)\n",
    "\n",
    "x_valid = x_valid_orig.reshape(x_valid_orig.shape[0], -1).astype('float32')/255.\n",
    "y_valid = data_format(y_valid_orig)\n",
    "\n",
    "x_test = x_test_orig.reshape(x_test_orig.shape[0], -1).astype('float32')/255.\n",
    "y_test = data_format(y_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_compute(y, pred):\n",
    "    #error = - np.sum(np.diagonal(y.dot(np.log(pred+1e-10).T)))\n",
    "    # y pred in N*10\n",
    "    #error = np.mean(np.sum((y-pred)**2, axis=1))\n",
    "    N = np.shape(y)[0]\n",
    "    y_index = np.argmax(y, 1)\n",
    "    pred_index = np.argmax(pred, 1)\n",
    "    error = np.linalg.norm((y_index-pred_index), ord=2)/N\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_compute(y, pred): \n",
    "    y_index = np.argmax(y, 1)\n",
    "    pred_index = np.argmax(pred, 1)\n",
    "    accuracy = np.mean((pred_index==y_index).astype('int'))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "# Neural network \n",
    "\n",
    "def NN_define(input_size = 784, m_size = 2**5, output_size = 1): \n",
    "    # encoding \n",
    "    input_img = tf.keras.Input(shape=(input_size,))\n",
    "\n",
    "\n",
    "    # middle layer \n",
    "    activation = tf.math.cos \n",
    "    m_layer = Dense(m_size, activation=activation)(input_img)\n",
    "    #m_layer = Dense(m_size, activation='relu')(h2_layer)\n",
    "\n",
    "    output_img = Dense(output_size, activation='linear')(m_layer)\n",
    "\n",
    "    model = Model(input_img, output_img)\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(tf.keras.callbacks.Callback): \n",
    "    \n",
    "    def __init__(self, epochs, name): \n",
    "        self.epochs = epochs  \n",
    "        self.name = name\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        \n",
    "        global pred_train, pred_valid, pred_test\n",
    "        global i \n",
    "            \n",
    "        pred_train[epoch-1, i] = model.predict(x_train).flatten()\n",
    "        pred_valid[epoch-1, i] = model.predict(x_valid).flatten()\n",
    "        pred_test[epoch-1, i] = model.predict(x_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              803840    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 804,865\n",
      "Trainable params: 804,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0693 - accuracy: 0.9356 - val_loss: 0.1565 - val_accuracy: 0.8591\n",
      "Epoch 2/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0421 - accuracy: 0.9664 - val_loss: 0.1500 - val_accuracy: 0.8409\n",
      "Epoch 3/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0367 - accuracy: 0.9715 - val_loss: 0.1551 - val_accuracy: 0.8430\n",
      "Epoch 4/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0348 - accuracy: 0.9752 - val_loss: 0.1551 - val_accuracy: 0.8345\n",
      "Epoch 5/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0330 - accuracy: 0.9772 - val_loss: 0.1630 - val_accuracy: 0.8437\n",
      "Epoch 6/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0298 - accuracy: 0.9792 - val_loss: 0.1717 - val_accuracy: 0.8457\n",
      "Epoch 7/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0277 - accuracy: 0.9804 - val_loss: 0.1597 - val_accuracy: 0.8314\n",
      "Epoch 8/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0281 - accuracy: 0.9816 - val_loss: 0.1582 - val_accuracy: 0.8365\n",
      "Epoch 9/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0260 - accuracy: 0.9822 - val_loss: 0.1604 - val_accuracy: 0.8391\n",
      "Epoch 10/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0253 - accuracy: 0.9836 - val_loss: 0.1581 - val_accuracy: 0.8353\n",
      "Epoch 11/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0257 - accuracy: 0.9830 - val_loss: 0.1605 - val_accuracy: 0.8377\n",
      "Epoch 12/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0267 - accuracy: 0.9831 - val_loss: 0.2660 - val_accuracy: 0.7942\n",
      "Epoch 13/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0256 - accuracy: 0.9841 - val_loss: 0.1704 - val_accuracy: 0.8416\n",
      "Epoch 14/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0239 - accuracy: 0.9846 - val_loss: 0.1611 - val_accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0228 - accuracy: 0.9852 - val_loss: 0.1887 - val_accuracy: 0.8447\n",
      "Epoch 16/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0235 - accuracy: 0.9853 - val_loss: 0.1616 - val_accuracy: 0.8349\n",
      "Epoch 17/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0224 - accuracy: 0.9859 - val_loss: 0.2577 - val_accuracy: 0.8019\n",
      "Epoch 18/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0219 - accuracy: 0.9867 - val_loss: 0.5089 - val_accuracy: 0.1433\n",
      "Epoch 19/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0231 - accuracy: 0.9850 - val_loss: 0.1661 - val_accuracy: 0.8362\n",
      "Epoch 20/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0215 - accuracy: 0.9870 - val_loss: 0.1625 - val_accuracy: 0.8341\n",
      "Epoch 21/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0203 - accuracy: 0.9878 - val_loss: 0.1984 - val_accuracy: 0.8438\n",
      "Epoch 22/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0209 - accuracy: 0.9879 - val_loss: 0.1687 - val_accuracy: 0.8355\n",
      "Epoch 23/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0202 - accuracy: 0.9882 - val_loss: 0.1844 - val_accuracy: 0.8232\n",
      "Epoch 24/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0200 - accuracy: 0.9882 - val_loss: 0.1625 - val_accuracy: 0.8296\n",
      "Epoch 25/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0192 - accuracy: 0.9890 - val_loss: 0.1623 - val_accuracy: 0.8314\n",
      "Epoch 26/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0198 - accuracy: 0.9893 - val_loss: 0.1752 - val_accuracy: 0.8250\n",
      "Epoch 27/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0187 - accuracy: 0.9898 - val_loss: 0.2016 - val_accuracy: 0.8417\n",
      "Epoch 28/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0183 - accuracy: 0.9901 - val_loss: 0.1665 - val_accuracy: 0.8274\n",
      "Epoch 29/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0180 - accuracy: 0.9900 - val_loss: 0.1688 - val_accuracy: 0.8262\n",
      "Epoch 30/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0178 - accuracy: 0.9905 - val_loss: 0.1654 - val_accuracy: 0.8311\n",
      "Epoch 31/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0180 - accuracy: 0.9907 - val_loss: 0.1658 - val_accuracy: 0.8272\n",
      "Epoch 32/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0179 - accuracy: 0.9909 - val_loss: 0.1688 - val_accuracy: 0.8262\n",
      "Epoch 33/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0166 - accuracy: 0.9909 - val_loss: 0.1646 - val_accuracy: 0.8295\n",
      "Epoch 34/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0178 - accuracy: 0.9908 - val_loss: 0.2063 - val_accuracy: 0.8192\n",
      "Epoch 35/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0171 - accuracy: 0.9908 - val_loss: 0.1657 - val_accuracy: 0.8273\n",
      "Epoch 36/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0172 - accuracy: 0.9909 - val_loss: 0.1663 - val_accuracy: 0.8281\n",
      "Epoch 37/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0161 - accuracy: 0.9914 - val_loss: 0.1903 - val_accuracy: 0.8214\n",
      "Epoch 38/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0166 - accuracy: 0.9918 - val_loss: 0.1662 - val_accuracy: 0.8271\n",
      "Epoch 39/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0162 - accuracy: 0.9916 - val_loss: 0.2035 - val_accuracy: 0.8195\n",
      "Epoch 40/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0166 - accuracy: 0.9911 - val_loss: 0.1749 - val_accuracy: 0.8318\n",
      "Epoch 41/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0159 - accuracy: 0.9919 - val_loss: 0.2025 - val_accuracy: 0.8198\n",
      "Epoch 42/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0153 - accuracy: 0.9921 - val_loss: 0.1695 - val_accuracy: 0.8303\n",
      "Epoch 43/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0166 - accuracy: 0.9916 - val_loss: 0.1693 - val_accuracy: 0.8259\n",
      "Epoch 44/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0165 - accuracy: 0.9918 - val_loss: 0.1755 - val_accuracy: 0.8319\n",
      "Epoch 45/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0154 - accuracy: 0.9919 - val_loss: 0.1711 - val_accuracy: 0.8308\n",
      "Epoch 46/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0163 - accuracy: 0.9917 - val_loss: 0.1755 - val_accuracy: 0.8243\n",
      "Epoch 47/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0166 - accuracy: 0.9916 - val_loss: 0.1652 - val_accuracy: 0.8279\n",
      "Epoch 48/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0153 - accuracy: 0.9922 - val_loss: 0.1672 - val_accuracy: 0.8265\n",
      "Epoch 49/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0150 - accuracy: 0.9922 - val_loss: 0.1724 - val_accuracy: 0.8311\n",
      "Epoch 50/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0159 - accuracy: 0.9924 - val_loss: 0.1695 - val_accuracy: 0.8294\n",
      "Epoch 51/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0156 - accuracy: 0.9921 - val_loss: 0.1868 - val_accuracy: 0.8223\n",
      "Epoch 52/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0158 - accuracy: 0.9918 - val_loss: 0.1655 - val_accuracy: 0.8279\n",
      "Epoch 53/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0144 - accuracy: 0.9929 - val_loss: 0.1667 - val_accuracy: 0.8285\n",
      "Epoch 54/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0145 - accuracy: 0.9925 - val_loss: 0.1670 - val_accuracy: 0.8285\n",
      "Epoch 55/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0147 - accuracy: 0.9927 - val_loss: 0.1662 - val_accuracy: 0.8283\n",
      "Epoch 56/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0147 - accuracy: 0.9924 - val_loss: 0.1676 - val_accuracy: 0.8279\n",
      "Epoch 57/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0144 - accuracy: 0.9929 - val_loss: 0.1914 - val_accuracy: 0.8215\n",
      "Epoch 58/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 0.1670 - val_accuracy: 0.8266\n",
      "Epoch 59/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0145 - accuracy: 0.9928 - val_loss: 0.1672 - val_accuracy: 0.8282\n",
      "Epoch 60/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0151 - accuracy: 0.9926 - val_loss: 0.1967 - val_accuracy: 0.8350\n",
      "Epoch 61/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0153 - accuracy: 0.9924 - val_loss: 0.1673 - val_accuracy: 0.8266\n",
      "Epoch 62/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0147 - accuracy: 0.9928 - val_loss: 0.1670 - val_accuracy: 0.8279\n",
      "Epoch 63/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0146 - accuracy: 0.9928 - val_loss: 0.1697 - val_accuracy: 0.8290\n",
      "Epoch 64/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0143 - accuracy: 0.9928 - val_loss: 0.1721 - val_accuracy: 0.8250\n",
      "Epoch 65/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0147 - accuracy: 0.9927 - val_loss: 0.1739 - val_accuracy: 0.8302\n",
      "Epoch 66/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0148 - accuracy: 0.9927 - val_loss: 0.1675 - val_accuracy: 0.8279\n",
      "Epoch 67/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0138 - accuracy: 0.9929 - val_loss: 0.1665 - val_accuracy: 0.8275\n",
      "Epoch 68/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0142 - accuracy: 0.9931 - val_loss: 0.1701 - val_accuracy: 0.8289\n",
      "Epoch 69/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.1836 - val_accuracy: 0.8323\n",
      "Epoch 70/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0143 - accuracy: 0.9930 - val_loss: 0.1692 - val_accuracy: 0.8257\n",
      "Epoch 71/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0144 - accuracy: 0.9932 - val_loss: 0.1692 - val_accuracy: 0.8280\n",
      "Epoch 72/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0135 - accuracy: 0.9935 - val_loss: 0.2083 - val_accuracy: 0.8189\n",
      "Epoch 73/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0140 - accuracy: 0.9931 - val_loss: 0.1667 - val_accuracy: 0.8279\n",
      "Epoch 74/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0141 - accuracy: 0.9935 - val_loss: 0.1662 - val_accuracy: 0.8275\n",
      "Epoch 75/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0136 - accuracy: 0.9931 - val_loss: 0.1714 - val_accuracy: 0.8292\n",
      "Epoch 76/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0130 - accuracy: 0.9932 - val_loss: 0.1750 - val_accuracy: 0.8301\n",
      "Epoch 77/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0134 - accuracy: 0.9936 - val_loss: 0.1679 - val_accuracy: 0.8285\n",
      "Epoch 78/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0130 - accuracy: 0.9933 - val_loss: 0.1678 - val_accuracy: 0.8273\n",
      "Epoch 79/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0133 - accuracy: 0.9936 - val_loss: 0.1827 - val_accuracy: 0.8229\n",
      "Epoch 80/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0136 - accuracy: 0.9935 - val_loss: 0.1669 - val_accuracy: 0.8266\n",
      "Epoch 81/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0132 - accuracy: 0.9935 - val_loss: 0.1919 - val_accuracy: 0.8217\n",
      "Epoch 82/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0130 - accuracy: 0.9940 - val_loss: 0.1890 - val_accuracy: 0.8222\n",
      "Epoch 83/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0142 - accuracy: 0.9931 - val_loss: 0.1686 - val_accuracy: 0.8281\n",
      "Epoch 84/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0137 - accuracy: 0.9933 - val_loss: 0.1759 - val_accuracy: 0.8305\n",
      "Epoch 85/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9938 - val_loss: 0.1728 - val_accuracy: 0.8249\n",
      "Epoch 86/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0137 - accuracy: 0.9935 - val_loss: 0.1732 - val_accuracy: 0.8247\n",
      "Epoch 87/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0136 - accuracy: 0.9939 - val_loss: 0.1680 - val_accuracy: 0.8280\n",
      "Epoch 88/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9935 - val_loss: 0.1761 - val_accuracy: 0.8299\n",
      "Epoch 89/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9934 - val_loss: 0.1676 - val_accuracy: 0.8262\n",
      "Epoch 90/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0136 - accuracy: 0.9933 - val_loss: 0.2166 - val_accuracy: 0.8365\n",
      "Epoch 91/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0136 - accuracy: 0.9938 - val_loss: 0.1751 - val_accuracy: 0.8296\n",
      "Epoch 92/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0125 - accuracy: 0.9939 - val_loss: 0.1791 - val_accuracy: 0.8234\n",
      "Epoch 93/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0123 - accuracy: 0.9940 - val_loss: 0.1697 - val_accuracy: 0.8283\n",
      "Epoch 94/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0133 - accuracy: 0.9939 - val_loss: 0.1702 - val_accuracy: 0.8285\n",
      "Epoch 95/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0135 - accuracy: 0.9939 - val_loss: 0.1678 - val_accuracy: 0.8266\n",
      "Epoch 96/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0127 - accuracy: 0.9939 - val_loss: 0.1765 - val_accuracy: 0.8239\n",
      "Epoch 97/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0132 - accuracy: 0.9941 - val_loss: 0.1688 - val_accuracy: 0.8258\n",
      "Epoch 98/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0134 - accuracy: 0.9938 - val_loss: 0.1720 - val_accuracy: 0.8286\n",
      "Epoch 99/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0132 - accuracy: 0.9938 - val_loss: 0.1728 - val_accuracy: 0.8288\n",
      "Epoch 100/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0131 - accuracy: 0.9939 - val_loss: 0.1689 - val_accuracy: 0.8283\n",
      "Epoch 1/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.1131 - accuracy: 0.8800 - val_loss: 0.1558 - val_accuracy: 0.8798\n",
      "Epoch 2/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0711 - accuracy: 0.9382 - val_loss: 0.2405 - val_accuracy: 0.7127\n",
      "Epoch 3/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0561 - accuracy: 0.9584 - val_loss: 0.1823 - val_accuracy: 0.8459\n",
      "Epoch 4/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0448 - accuracy: 0.9702 - val_loss: 0.1657 - val_accuracy: 0.8081\n",
      "Epoch 5/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0394 - accuracy: 0.9762 - val_loss: 0.1883 - val_accuracy: 0.7961\n",
      "Epoch 6/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0360 - accuracy: 0.9787 - val_loss: 0.1831 - val_accuracy: 0.8003\n",
      "Epoch 7/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0335 - accuracy: 0.9816 - val_loss: 0.1714 - val_accuracy: 0.8183\n",
      "Epoch 8/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0297 - accuracy: 0.9841 - val_loss: 0.1704 - val_accuracy: 0.8126\n",
      "Epoch 9/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0293 - accuracy: 0.9847 - val_loss: 0.1860 - val_accuracy: 0.8019\n",
      "Epoch 10/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0273 - accuracy: 0.9861 - val_loss: 0.1748 - val_accuracy: 0.8080\n",
      "Epoch 11/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0251 - accuracy: 0.9872 - val_loss: 0.1882 - val_accuracy: 0.8028\n",
      "Epoch 12/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0246 - accuracy: 0.9884 - val_loss: 0.1799 - val_accuracy: 0.8147\n",
      "Epoch 13/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0229 - accuracy: 0.9895 - val_loss: 0.1803 - val_accuracy: 0.8147\n",
      "Epoch 14/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0226 - accuracy: 0.9898 - val_loss: 0.1896 - val_accuracy: 0.8035\n",
      "Epoch 15/100\n",
      "1532/1532 [==============================] - 13s 9ms/step - loss: 0.0229 - accuracy: 0.9894 - val_loss: 0.1781 - val_accuracy: 0.8089\n",
      "Epoch 16/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0220 - accuracy: 0.9900 - val_loss: 0.2023 - val_accuracy: 0.8014\n",
      "Epoch 17/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0213 - accuracy: 0.9906 - val_loss: 0.1884 - val_accuracy: 0.8159\n",
      "Epoch 18/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0212 - accuracy: 0.9904 - val_loss: 0.1931 - val_accuracy: 0.8035\n",
      "Epoch 19/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0204 - accuracy: 0.9911 - val_loss: 0.2227 - val_accuracy: 0.8248\n",
      "Epoch 20/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0200 - accuracy: 0.9914 - val_loss: 0.1792 - val_accuracy: 0.8094\n",
      "Epoch 21/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0197 - accuracy: 0.9917 - val_loss: 0.1929 - val_accuracy: 0.8043\n",
      "Epoch 22/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0204 - accuracy: 0.9909 - val_loss: 0.2477 - val_accuracy: 0.7924\n",
      "Epoch 23/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0185 - accuracy: 0.9916 - val_loss: 0.1863 - val_accuracy: 0.8133\n",
      "Epoch 24/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0183 - accuracy: 0.9923 - val_loss: 0.2008 - val_accuracy: 0.8030\n",
      "Epoch 25/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.1818 - val_accuracy: 0.8085\n",
      "Epoch 26/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 0.1810 - val_accuracy: 0.8086\n",
      "Epoch 27/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.2008 - val_accuracy: 0.8166\n",
      "Epoch 28/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0176 - accuracy: 0.9925 - val_loss: 0.1816 - val_accuracy: 0.8093\n",
      "Epoch 29/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0177 - accuracy: 0.9925 - val_loss: 0.1893 - val_accuracy: 0.8135\n",
      "Epoch 30/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0169 - accuracy: 0.9929 - val_loss: 0.1814 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.1843 - val_accuracy: 0.8073\n",
      "Epoch 32/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0171 - accuracy: 0.9928 - val_loss: 0.1814 - val_accuracy: 0.8101\n",
      "Epoch 33/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0172 - accuracy: 0.9923 - val_loss: 0.1819 - val_accuracy: 0.8086\n",
      "Epoch 34/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0158 - accuracy: 0.9935 - val_loss: 0.1827 - val_accuracy: 0.8085\n",
      "Epoch 35/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0169 - accuracy: 0.9931 - val_loss: 0.1819 - val_accuracy: 0.8091\n",
      "Epoch 36/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 0.1868 - val_accuracy: 0.8120\n",
      "Epoch 37/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0160 - accuracy: 0.9932 - val_loss: 0.1992 - val_accuracy: 0.8153\n",
      "Epoch 38/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.1834 - val_accuracy: 0.8110\n",
      "Epoch 39/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0163 - accuracy: 0.9934 - val_loss: 0.1840 - val_accuracy: 0.8078\n",
      "Epoch 40/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0160 - accuracy: 0.9932 - val_loss: 0.2236 - val_accuracy: 0.8203\n",
      "Epoch 41/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0155 - accuracy: 0.9933 - val_loss: 0.1840 - val_accuracy: 0.8082\n",
      "Epoch 42/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0149 - accuracy: 0.9937 - val_loss: 0.1844 - val_accuracy: 0.8109\n",
      "Epoch 43/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.2155 - val_accuracy: 0.8025\n",
      "Epoch 44/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.1833 - val_accuracy: 0.8086\n",
      "Epoch 45/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0157 - accuracy: 0.9936 - val_loss: 0.1836 - val_accuracy: 0.8090\n",
      "Epoch 46/100\n",
      "1532/1532 [==============================] - 11s 7ms/step - loss: 0.0151 - accuracy: 0.9937 - val_loss: 0.1824 - val_accuracy: 0.8095\n",
      "Epoch 47/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0150 - accuracy: 0.9940 - val_loss: 0.2076 - val_accuracy: 0.8040\n",
      "Epoch 48/100\n",
      "1532/1532 [==============================] - 7s 5ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.1843 - val_accuracy: 0.8105\n",
      "Epoch 49/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0149 - accuracy: 0.9939 - val_loss: 0.1831 - val_accuracy: 0.8095\n",
      "Epoch 50/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0145 - accuracy: 0.9940 - val_loss: 0.1898 - val_accuracy: 0.8066\n",
      "Epoch 51/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0146 - accuracy: 0.9939 - val_loss: 0.1986 - val_accuracy: 0.8054\n",
      "Epoch 52/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0149 - accuracy: 0.9940 - val_loss: 0.1836 - val_accuracy: 0.8094\n",
      "Epoch 53/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0145 - accuracy: 0.9940 - val_loss: 0.1851 - val_accuracy: 0.8110\n",
      "Epoch 54/100\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 0.0148 - accuracy: 0.9941 - val_loss: 0.1826 - val_accuracy: 0.8089\n",
      "Epoch 55/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 0.1846 - val_accuracy: 0.8103\n",
      "Epoch 56/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0142 - accuracy: 0.9941 - val_loss: 0.1839 - val_accuracy: 0.8086\n",
      "Epoch 57/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0142 - accuracy: 0.9943 - val_loss: 0.1976 - val_accuracy: 0.8056\n",
      "Epoch 58/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.1918 - val_accuracy: 0.8066\n",
      "Epoch 59/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0141 - accuracy: 0.9943 - val_loss: 0.2063 - val_accuracy: 0.8045\n",
      "Epoch 60/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0146 - accuracy: 0.9943 - val_loss: 0.1850 - val_accuracy: 0.8082\n",
      "Epoch 61/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.1993 - val_accuracy: 0.8055\n",
      "Epoch 62/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.1954 - val_accuracy: 0.8059\n",
      "Epoch 63/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.1830 - val_accuracy: 0.8092\n",
      "Epoch 64/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0132 - accuracy: 0.9943 - val_loss: 0.1842 - val_accuracy: 0.8101\n",
      "Epoch 65/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0146 - accuracy: 0.9942 - val_loss: 0.3077 - val_accuracy: 0.7793\n",
      "Epoch 66/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.1894 - val_accuracy: 0.8071\n",
      "Epoch 67/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.1842 - val_accuracy: 0.8081\n",
      "Epoch 68/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0131 - accuracy: 0.9943 - val_loss: 0.1964 - val_accuracy: 0.8127\n",
      "Epoch 69/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.1887 - val_accuracy: 0.8071\n",
      "Epoch 70/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0132 - accuracy: 0.9946 - val_loss: 0.1843 - val_accuracy: 0.8092\n",
      "Epoch 71/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.1888 - val_accuracy: 0.8071\n",
      "Epoch 72/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0140 - accuracy: 0.9945 - val_loss: 0.1894 - val_accuracy: 0.8070\n",
      "Epoch 73/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.1988 - val_accuracy: 0.8056\n",
      "Epoch 74/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1869 - val_accuracy: 0.8077\n",
      "Epoch 75/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0131 - accuracy: 0.9948 - val_loss: 0.1912 - val_accuracy: 0.8067\n",
      "Epoch 76/100\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.1837 - val_accuracy: 0.8095\n",
      "Epoch 77/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.2307 - val_accuracy: 0.8009\n",
      "Epoch 78/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.1845 - val_accuracy: 0.8086\n",
      "Epoch 79/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0133 - accuracy: 0.9945 - val_loss: 0.1922 - val_accuracy: 0.8114\n",
      "Epoch 80/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.1863 - val_accuracy: 0.8078\n",
      "Epoch 81/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.1858 - val_accuracy: 0.8078\n",
      "Epoch 82/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0131 - accuracy: 0.9946 - val_loss: 0.1911 - val_accuracy: 0.8112\n",
      "Epoch 83/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0136 - accuracy: 0.9944 - val_loss: 0.1843 - val_accuracy: 0.8090\n",
      "Epoch 84/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.1916 - val_accuracy: 0.8113\n",
      "Epoch 85/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.1855 - val_accuracy: 0.8101\n",
      "Epoch 86/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0122 - accuracy: 0.9950 - val_loss: 0.1856 - val_accuracy: 0.8078\n",
      "Epoch 87/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1881 - val_accuracy: 0.8073\n",
      "Epoch 88/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.1861 - val_accuracy: 0.8078\n",
      "Epoch 89/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0126 - accuracy: 0.9950 - val_loss: 0.1921 - val_accuracy: 0.8113\n",
      "Epoch 90/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.1855 - val_accuracy: 0.8099\n",
      "Epoch 91/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0122 - accuracy: 0.9951 - val_loss: 0.1849 - val_accuracy: 0.8080\n",
      "Epoch 92/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.1929 - val_accuracy: 0.8067\n",
      "Epoch 93/100\n",
      "1532/1532 [==============================] - 15s 9ms/step - loss: 0.0127 - accuracy: 0.9948 - val_loss: 0.1899 - val_accuracy: 0.8111\n",
      "Epoch 94/100\n",
      "1532/1532 [==============================] - 16s 10ms/step - loss: 0.0120 - accuracy: 0.9950 - val_loss: 0.1914 - val_accuracy: 0.8111\n",
      "Epoch 95/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0126 - accuracy: 0.9949 - val_loss: 0.1867 - val_accuracy: 0.8075\n",
      "Epoch 96/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.1902 - val_accuracy: 0.8071\n",
      "Epoch 97/100\n",
      "1532/1532 [==============================] - 15s 10ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.1848 - val_accuracy: 0.8084\n",
      "Epoch 98/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.1867 - val_accuracy: 0.8077\n",
      "Epoch 99/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.1901 - val_accuracy: 0.8109\n",
      "Epoch 100/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0123 - accuracy: 0.9950 - val_loss: 0.1844 - val_accuracy: 0.8086\n",
      "Epoch 1/100\n",
      "1532/1532 [==============================] - 13s 8ms/step - loss: 0.1381 - accuracy: 0.8574 - val_loss: 0.1775 - val_accuracy: 0.7614\n",
      "Epoch 2/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0823 - accuracy: 0.9210 - val_loss: 0.1677 - val_accuracy: 0.8748\n",
      "Epoch 3/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0637 - accuracy: 0.9412 - val_loss: 0.1641 - val_accuracy: 0.8695\n",
      "Epoch 4/100\n",
      "1532/1532 [==============================] - 11s 7ms/step - loss: 0.0562 - accuracy: 0.9505 - val_loss: 0.1412 - val_accuracy: 0.8535\n",
      "Epoch 5/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0524 - accuracy: 0.9543 - val_loss: 0.1593 - val_accuracy: 0.8617\n",
      "Epoch 6/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0485 - accuracy: 0.9591 - val_loss: 0.2005 - val_accuracy: 0.8704\n",
      "Epoch 7/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0464 - accuracy: 0.9609 - val_loss: 0.1459 - val_accuracy: 0.8511\n",
      "Epoch 8/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0443 - accuracy: 0.9631 - val_loss: 0.1772 - val_accuracy: 0.8627\n",
      "Epoch 9/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0429 - accuracy: 0.9647 - val_loss: 0.1508 - val_accuracy: 0.8520\n",
      "Epoch 10/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0424 - accuracy: 0.9651 - val_loss: 0.1520 - val_accuracy: 0.8366\n",
      "Epoch 11/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0412 - accuracy: 0.9660 - val_loss: 0.1906 - val_accuracy: 0.8626\n",
      "Epoch 12/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0418 - accuracy: 0.9669 - val_loss: 0.1578 - val_accuracy: 0.8318\n",
      "Epoch 13/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0389 - accuracy: 0.9679 - val_loss: 0.1603 - val_accuracy: 0.8526\n",
      "Epoch 14/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0369 - accuracy: 0.9695 - val_loss: 0.1528 - val_accuracy: 0.8341\n",
      "Epoch 15/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0368 - accuracy: 0.9704 - val_loss: 0.1522 - val_accuracy: 0.8348\n",
      "Epoch 16/100\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 0.0359 - accuracy: 0.9710 - val_loss: 0.1711 - val_accuracy: 0.8262\n",
      "Epoch 17/100\n",
      "1532/1532 [==============================] - 13s 9ms/step - loss: 0.0350 - accuracy: 0.9726 - val_loss: 0.1609 - val_accuracy: 0.8492\n",
      "Epoch 18/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0338 - accuracy: 0.9727 - val_loss: 0.1758 - val_accuracy: 0.8243\n",
      "Epoch 19/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0342 - accuracy: 0.9726 - val_loss: 0.1556 - val_accuracy: 0.8313\n",
      "Epoch 20/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0333 - accuracy: 0.9734 - val_loss: 0.1554 - val_accuracy: 0.8448\n",
      "Epoch 21/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0320 - accuracy: 0.9746 - val_loss: 0.1983 - val_accuracy: 0.8173\n",
      "Epoch 22/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0318 - accuracy: 0.9744 - val_loss: 0.1541 - val_accuracy: 0.8327\n",
      "Epoch 23/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0320 - accuracy: 0.9750 - val_loss: 0.1552 - val_accuracy: 0.8316\n",
      "Epoch 24/100\n",
      "1532/1532 [==============================] - 12s 8ms/step - loss: 0.0311 - accuracy: 0.9755 - val_loss: 0.1540 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 0.0320 - accuracy: 0.9754 - val_loss: 0.1532 - val_accuracy: 0.8341\n",
      "Epoch 26/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0306 - accuracy: 0.9763 - val_loss: 0.1539 - val_accuracy: 0.8323\n",
      "Epoch 27/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0303 - accuracy: 0.9769 - val_loss: 0.2133 - val_accuracy: 0.8583\n",
      "Epoch 28/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0286 - accuracy: 0.9775 - val_loss: 0.2682 - val_accuracy: 0.8681\n",
      "Epoch 29/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0289 - accuracy: 0.9773 - val_loss: 0.1574 - val_accuracy: 0.8298\n",
      "Epoch 30/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0288 - accuracy: 0.9773 - val_loss: 0.1561 - val_accuracy: 0.8305\n",
      "Epoch 31/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0280 - accuracy: 0.9783 - val_loss: 0.1544 - val_accuracy: 0.8339\n",
      "Epoch 32/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0277 - accuracy: 0.9791 - val_loss: 0.1565 - val_accuracy: 0.8301\n",
      "Epoch 33/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0267 - accuracy: 0.9791 - val_loss: 0.1785 - val_accuracy: 0.8227\n",
      "Epoch 34/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0280 - accuracy: 0.9787 - val_loss: 0.1657 - val_accuracy: 0.8425\n",
      "Epoch 35/100\n",
      "1532/1532 [==============================] - 10s 6ms/step - loss: 0.0272 - accuracy: 0.9799 - val_loss: 0.1567 - val_accuracy: 0.8295\n",
      "Epoch 36/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0277 - accuracy: 0.9794 - val_loss: 0.1554 - val_accuracy: 0.8345\n",
      "Epoch 37/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0265 - accuracy: 0.9800 - val_loss: 0.1740 - val_accuracy: 0.8446\n",
      "Epoch 38/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0265 - accuracy: 0.9804 - val_loss: 0.1556 - val_accuracy: 0.8326\n",
      "Epoch 39/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0258 - accuracy: 0.9807 - val_loss: 0.1664 - val_accuracy: 0.8415\n",
      "Epoch 40/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0256 - accuracy: 0.9806 - val_loss: 0.1569 - val_accuracy: 0.8299\n",
      "Epoch 41/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0260 - accuracy: 0.9810 - val_loss: 0.1600 - val_accuracy: 0.8277\n",
      "Epoch 42/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0257 - accuracy: 0.9822 - val_loss: 0.1716 - val_accuracy: 0.8420\n",
      "Epoch 43/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0249 - accuracy: 0.9817 - val_loss: 0.1622 - val_accuracy: 0.8368\n",
      "Epoch 44/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0247 - accuracy: 0.9818 - val_loss: 0.1585 - val_accuracy: 0.8336\n",
      "Epoch 45/100\n",
      "1532/1532 [==============================] - 8s 6ms/step - loss: 0.0245 - accuracy: 0.9826 - val_loss: 0.2248 - val_accuracy: 0.8073\n",
      "Epoch 46/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0243 - accuracy: 0.9828 - val_loss: 0.1615 - val_accuracy: 0.8266\n",
      "Epoch 47/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0249 - accuracy: 0.9828 - val_loss: 0.1809 - val_accuracy: 0.8210\n",
      "Epoch 48/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0247 - accuracy: 0.9826 - val_loss: 0.1580 - val_accuracy: 0.8298\n",
      "Epoch 49/100\n",
      "1532/1532 [==============================] - 9s 6ms/step - loss: 0.0251 - accuracy: 0.9828 - val_loss: 0.1641 - val_accuracy: 0.8361\n",
      "Epoch 50/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0242 - accuracy: 0.9830 - val_loss: 0.1625 - val_accuracy: 0.8257\n",
      "Epoch 51/100\n",
      "1532/1532 [==============================] - 8s 5ms/step - loss: 0.0243 - accuracy: 0.9834 - val_loss: 0.1609 - val_accuracy: 0.8340\n",
      "Epoch 52/100\n",
      "1532/1532 [==============================] - 10s 7ms/step - loss: 0.0237 - accuracy: 0.9832 - val_loss: 0.1695 - val_accuracy: 0.8386\n",
      "Epoch 53/100\n",
      "1532/1532 [==============================] - 14s 9ms/step - loss: 0.0249 - accuracy: 0.9834 - val_loss: 0.1723 - val_accuracy: 0.8395\n",
      "Epoch 54/100\n",
      "1532/1532 [==============================] - 15s 10ms/step - loss: 0.0229 - accuracy: 0.9840 - val_loss: 0.1616 - val_accuracy: 0.8332\n",
      "Epoch 55/100\n",
      "1532/1532 [==============================] - 16s 10ms/step - loss: 0.0226 - accuracy: 0.9839 - val_loss: 0.1596 - val_accuracy: 0.8290\n",
      "Epoch 56/100\n",
      "1319/1532 [========================>.....] - ETA: 1s - loss: 0.0231 - accuracy: 0.9836"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-e89b893d6177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     model.fit(x=x_train, y=y_train[:,i], \n\u001b[0m\u001b[0;32m     23\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "K = 2**10\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = NN_define(input_size = 784, m_size = K, output_size = 1)\n",
    "model.compile(loss='mse', \n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "N_train = np.shape(x_train)[0]\n",
    "pred_train = np.zeros(epochs*10*N_train).reshape(epochs, 10, N_train)\n",
    "N_valid = np.shape(x_valid)[0]\n",
    "pred_valid = np.zeros(epochs*10*N_valid).reshape(epochs, 10, N_valid)\n",
    "N_test = np.shape(x_test)[0]\n",
    "pred_test = np.zeros(epochs*10*N_test).reshape(epochs, 10, N_test)\n",
    "\n",
    "\n",
    "history = CustomCallback(epochs, model)\n",
    "\n",
    "for i in range(10): \n",
    "    model.fit(x=x_train, y=y_train[:,i], \n",
    "          validation_data = (x_valid, y_valid), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size, \n",
    "          callbacks=[history])\n",
    "    \n",
    "error_train_list = []\n",
    "error_valid_list = []\n",
    "error_test_list = []\n",
    "    \n",
    "accuracy_train_list = []\n",
    "accuracy_valid_list = []\n",
    "accuracy_test_list = []\n",
    "    \n",
    "for m in range(epochs): \n",
    "    \n",
    "    error_train = error_compute(y_train, pred_train[m].T)\n",
    "    error_train_list = np.append(error_train_list, error_train)\n",
    "    accuracy_train = accuracy_compute(y_train, pred_train[m].T)\n",
    "    accuracy_train_list = np.append(accuracy_train_list, accuracy_train)\n",
    "        \n",
    "    error_valid= error_compute(y_valid, pred_valid[m].T)\n",
    "    error_valid_list = np.append(error_valid_list, error_valid)\n",
    "    accuracy_valid= accuracy_compute(y_valid, pred_valid[m].T)\n",
    "    accuracy_valid_list = np.append(accuracy_valid_list, accuracy_valid)\n",
    "        \n",
    "    error_test = error_compute(y_test, pred_test[m].T)\n",
    "    error_test_list = np.append(error_test_list, error_test)\n",
    "    accuracy_test = accuracy_compute(y_test, pred_test[m].T)\n",
    "    accuracy_test_list = np.append(accuracy_test_list, accuracy_test)\n",
    "\n",
    "np.savez('./sgd_1.npz', \n",
    "         pred_train = pred_train, \n",
    "         pred_valid = pred_valid, \n",
    "         pred_test = pred_test, \n",
    "         error_train_list = error_train_list, \n",
    "         error_valid_list = error_valid_list,\n",
    "         error_test_list = error_test_list,\n",
    "         accuracy_train_list = accuracy_train_list, \n",
    "         accuracy_valid_list = accuracy_valid_list, \n",
    "         accuracy_test_list = accuracy_test_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "epoch_list = np.arange(1, epochs+1)\n",
    "plt.subplot(1, 2,  1)\n",
    "plt.semilogy(epoch_list, error_train_list, label = 'training_loss')\n",
    "plt.semilogy(epoch_list, error_valid_list, label = 'validation_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epoch_list, accuracy_train_list*100, label = 'accuracy_loss')\n",
    "plt.plot(epoch_list, accuracy_valid_list*100, label = 'accuracy_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('%')\n",
    "plt.title('Accuracy')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./sgd_1.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
